{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce premier TP a pour objectif de se familiariser avec : python, numpy, matplotlib et les données. \n",
    "Pour cela, et si vous ne connaissez pas  python, numpy et matplotlib), il est **indispensable** de lire  le tutorial dans le répertoire /partage/allauzen/ter2017 sur ce sujet (cs228-python-tutorial.ipynb).\n",
    "\n",
    "\n",
    "# Les données\n",
    "\n",
    "Les données utilisées sont disponibles via keras (module que nous allons utiliser par la suite). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "start_index=3 \n",
    "vocab_size=10000 # or None for everything\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(path=\"imdb_full.pkl\",\n",
    "                                                      nb_words=vocab_size,\n",
    "                                                      skip_top=0,\n",
    "                                                      maxlen=None,\n",
    "                                                      seed=113,\n",
    "                                                      start_char=1,\n",
    "                                                      oov_char=3,\n",
    "                                                      index_from=start_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On dispose alors de 4 objets python: \n",
    "* X_train : les textes d'apprentissage\n",
    "* y_train : les classes affectées à chacun des textes\n",
    "* X_test et y_test représentent les données d'évaluation dont on se servira plus tard\n",
    "\n",
    "Dans un premier temps, nous allons regarder les données d'apprentissage.\n",
    "* Quel est le type de X_train, puis de  y_train ?\n",
    "* Combien y-a-t-il d'exemple d'apprentissage ? \n",
    "* Ces deux objets sont des conteneurs. Comment connaître le type des données stockées pour chacun d'entre eux ? \n",
    "* Comment accèder au premier texte ? et à sa classe ? \n",
    "* Que contient le premier texte ? Décrire son contenu \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>   (25000,)   object\n",
      "<type 'numpy.ndarray'>   (25000,)   int64\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 3, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 3, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 3, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 3, 8, 4, 107, 117, 5952, 15, 256, 4, 3, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 3, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# à vous de jouer\n",
    "print type(X_train), \" \", X_train.shape, \" \", X_train.dtype\n",
    "print type(y_train), \" \", y_train.shape, \" \", y_train.dtype\n",
    "print X_train[0]\n",
    "print y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous aurez remarquer que le texte est à déchiffrer. Pour cela il existe un dictionnaire associé au données: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n",
      "88584\n",
      "1\n",
      "6\n",
      "it   9\n",
      "is   6\n",
      "in   8\n",
      "of   4\n",
      "a   3\n",
      "br   7\n",
      "the   1\n",
      "and   2\n",
      "to   5\n"
     ]
    }
   ],
   "source": [
    "wrd2idx  = imdb.get_word_index()\n",
    "print type(wrd2idx)\n",
    "print len(wrd2idx)\n",
    "print wrd2idx['the']\n",
    "print wrd2idx['is']\n",
    "for k in wrd2idx.keys():\n",
    "    if wrd2idx[k]<10:\n",
    "        print k,\" \", wrd2idx[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorons ce dictionnaire:\n",
    "* Combien contient d'entrée (couple clé,valeur) ? \n",
    "* Que représentent  les clés et les valeurs ? \n",
    "\n",
    "Si nous souhaitons \"déchiffrer\" un texte, il faut inverser ce dictionnaire: \n",
    "* écrire une fonction qui prend en paramètre un dictionnaire et qui l'inverse. \n",
    "* écrire une fonction qui prend un texte et qui en retourne une version lisible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, les indices des mots **dans les textes** sont décallés par rapport à ceux du dictionnaire *wrd2idx* (de la valeur de start_index). De plus **dans les textes** l'index 1 correspond à un \"mot\" particulier qui représente le début de phrase (par exemple #s) et l'index 2 est réservé au mots qui sont hors du vocabulaire, que l'on peut représenter par le symbôle #oov. Cela vient du fait que lors du chargement des données, on a choisi de ne garder que les 10000 premiers mots qui sont les plus fréquents. Les autres sont alors remplacer par le symbôle d'index 3. Il faut en tenir compte pour obtenir un texte lisible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'this', 'film', 'was', 'just', 'brilliant', 'casting', 'location', 'scenery', 'story', 'direction', \"everyone's\", 'really', 'suited', 'the', 'part', 'they', 'played', 'and', 'you', 'could', 'just', 'imagine', 'being', 'there', 'robert', '<oov>', 'is', 'an', 'amazing', 'actor', 'and', 'now', 'the', 'same', 'being', 'director', '<oov>', 'father', 'came', 'from', 'the', 'same', 'scottish', 'island', 'as', 'myself', 'so', 'i', 'loved', 'the', 'fact', 'there', 'was', 'a', 'real', 'connection', 'with', 'this', 'film', 'the', 'witty', 'remarks', 'throughout', 'the', 'film', 'were', 'great', 'it', 'was', 'just', 'brilliant', 'so', 'much', 'that', 'i', 'bought', 'the', 'film', 'as', 'soon', 'as', 'it', 'was', 'released', 'for', '<oov>', 'and', 'would', 'recommend', 'it', 'to', 'everyone', 'to', 'watch', 'and', 'the', 'fly', 'fishing', 'was', 'amazing', 'really', 'cried', 'at', 'the', 'end', 'it', 'was', 'so', 'sad', 'and', 'you', 'know', 'what', 'they', 'say', 'if', 'you', 'cry', 'at', 'a', 'film', 'it', 'must', 'have', 'been', 'good', 'and', 'this', 'definitely', 'was', 'also', '<oov>', 'to', 'the', 'two', 'little', \"boy's\", 'that', 'played', 'the', '<oov>', 'of', 'norman', 'and', 'paul', 'they', 'were', 'just', 'brilliant', 'children', 'are', 'often', 'left', 'out', 'of', 'the', '<oov>', 'list', 'i', 'think', 'because', 'the', 'stars', 'that', 'play', 'them', 'all', 'grown', 'up', 'are', 'such', 'a', 'big', 'profile', 'for', 'the', 'whole', 'film', 'but', 'these', 'children', 'are', 'amazing', 'and', 'should', 'be', 'praised', 'for', 'what', 'they', 'have', 'done', \"don't\", 'you', 'think', 'the', 'whole', 'story', 'was', 'so', 'lovely', 'because', 'it', 'was', 'true', 'and', 'was', \"someone's\", 'life', 'after', 'all', 'that', 'was', 'shared', 'with', 'us', 'all']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "idx2wrd = {}\n",
    "idx2wrd[0]=\"<pad>\"\n",
    "idx2wrd[1]=\"<s>\"\n",
    "idx2wrd[2]=\"</s>\"\n",
    "idx2wrd[3]=\"<oov>\"\n",
    "\n",
    "for  key, value in wrd2idx.iteritems():\n",
    "    idx2wrd[value+start_index]=key\n",
    "    \n",
    "def readX( x, reader):\n",
    "    seqw = list()\n",
    "    for i in x:\n",
    "        wrd = reader[i]\n",
    "        seqw.append(wrd)\n",
    "    return seqw\n",
    "\n",
    "print readX( X_train[0], idx2wrd)\n",
    "print y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistiques\n",
    "Nous allons maintenant faire des statistiques élémentaires sur les données. \n",
    "* écrire une fonction qui prend en paramètres *X_train* et qui retourne un dictionnaire ou par chaque pour index de mot est associé son compte observé sur toutes les données. \n",
    "* tracer la courbe  associée avec en abscisse l'index du mot et en ordonnée le nombre d'occurence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# à vous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données\n",
    "\n",
    "Pour apprendre un modèle, il est souvent utile de convertir les données dans le format attendu par l'implémentation du modèle. Dans le cas de la régression logistique, les premières expériences vont utiliser une représentation en sac binaire des textes (voir le cours). \n",
    "\n",
    "* écrire une fonction qui convertit X_train en une matrice contenant tous les exemples d'apprentissage (chaque texte sera un ligne de la matrice, soit un vecteur). \n",
    "* écrire une fonction qui fait la même chose, mais avec les comptes de mots. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent2countVector (sentence): \n",
    "    v = np.zeros([vocab_size])\n",
    "    for i in range(1,len(sentence)):\n",
    "        v[sentence[i]-start_index]+=1 \n",
    "    return v\n",
    "\n",
    "\n",
    "def sent2binaryVector (sentence): \n",
    "    v = np.zeros([vocab_size])\n",
    "    for i in range(1,len(sentence)):\n",
    "        v[sentence[i]-start_index]=1 \n",
    "    return v\n",
    "\n",
    "def convertCorpus2binary(corpus):\n",
    "    M = np.zeros([len(corpus),vocab_size])\n",
    "    i=0\n",
    "    for x in corpus:\n",
    "        v = sent2binaryVector(x)\n",
    "        M[i,:] = v\n",
    "        i+=1\n",
    "    return M\n",
    "\n",
    "def convertCorpus2counts(corpus):\n",
    "    M = np.zeros([len(corpus),vocab_size])\n",
    "    i=0\n",
    "    for x in corpus:\n",
    "        v = sent2countVector(x)\n",
    "        M[i,:] = v\n",
    "        i+=1\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = convertCorpus2binary(X_train)\n",
    "test = convertCorpus2binary(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>   (25000, 10000)   float64\n",
      "<type 'numpy.ndarray'>   (25000, 10000)   float64\n"
     ]
    }
   ],
   "source": [
    "print type(train), \" \", train.shape, \" \", train.dtype\n",
    "print type(test), \" \", test.shape, \" \", test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
