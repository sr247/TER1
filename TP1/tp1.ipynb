{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce premier TP a pour objectif de se familiariser avec : python, numpy, matplotlib et les données. \n",
    "Pour cela, et si vous ne connaissez pas  python, numpy et matplotlib), il est **indispensable** de lire  le tutorial dans le répertoire /partage/allauzen/ter2017 sur ce sujet (cs228-python-tutorial.ipynb).\n",
    "\n",
    "\n",
    "# Les données\n",
    "\n",
    "Les données utilisées sont disponibles via keras (module que nous allons utiliser par la suite). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated.\n",
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_full.pkl\n",
      "65503232/65552540 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start_index=3 \n",
    "vocab_size=10000 # or None for everything\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(path=\"imdb_full.pkl\",\n",
    "                                                      nb_words=vocab_size,\n",
    "                                                      skip_top=0,\n",
    "                                                      maxlen=None,\n",
    "                                                      seed=113,\n",
    "                                                      start_char=1,\n",
    "                                                      oov_char=2, \n",
    "                                                      index_from=start_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On dispose alors de 4 objets python: \n",
    "* X_train : les textes d'apprentissage\n",
    "* y_train : les classes affectées à chacun des textes\n",
    "* X_test et y_test représentent les données d'évaluation dont on se servira plus tard\n",
    "\n",
    "Dans un premier temps, nous allons regarder les données d'apprentissage.\n",
    "* Quel est le type de X_train, puis de  y_train ?\n",
    "* Combien y-a-t-il d'exemple d'apprentissage ? \n",
    "* Ces deux objets sont des conteneurs. Comment connaître le type des données stockées pour chacun d'entre eux ? \n",
    "* Comment accèder au premier texte ? et à sa classe ? \n",
    "* Que contient le premier texte ? Décrire son contenu \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "25000\n",
      "object\n",
      "int64\n",
      "Affichage du 1er texte : \n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "Affichage de sa classe : 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Le premier texte contient des nombres\\n   Il semblerait que chaque nombre represente un mot\\n  '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# à vous de jouer\n",
    "print type(X_train)\n",
    "print type(y_train)\n",
    "print type(X_test)\n",
    "print type(y_test)\n",
    "print len(X_train)                                    # Il y a 20 000 exemples d'apprentissages\n",
    "print X_train.dtype                                   # L'objet dtype indique le type du contenu de la variable\n",
    "print y_train.dtype\n",
    "print 'Affichage du 1er texte : \\n' + str(X_train[0]) # Le texte 1\n",
    "print 'Affichage de sa classe : ' + str(y_train[0])   # La classe du texte 1 i.e W\n",
    "'''Le premier texte contient des nombres\n",
    "   Il semblerait que chaque nombre represente un mot\n",
    "  '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous aurez remarquer que le texte est à déchiffrer. Pour cela il existe un dictionnaire associé au données: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.pkl\n",
      "2351104/2343108 [==============================] - 1s     \n"
     ]
    }
   ],
   "source": [
    "wrd2idx  = imdb.get_word_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorons ce dictionnaire:\n",
    "* Combien contient d'entrée (couple clé,valeur) ? \n",
    "* Que représentent  les clés et les valeurs ? \n",
    "\n",
    "Si nous souhaitons \"déchiffrer\" un texte, il faut inverser ce dictionnaire: \n",
    "* écrire une fonction qui prend en paramètre un dictionnaire et qui l'inverse. \n",
    "* écrire une fonction qui prend un texte et qui en retourne une version lisible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, les indices des mots **dans les textes** sont décallés par rapport à ceux du dictionnaire *wrd2idx* (de la valeur de start_index). De plus **dans les textes** l'index 1 correspond à un \"mot\" particulier qui représente le début de phrase (par exemple #s) et l'index 2 est réservé au mots qui sont hors du vocabulaire, que l'on peut représenter par le symbôle #oov. Cela vient du fait que lors du chargement des données, on a choisi de ne garder que les 10000 premiers mots qui sont les plus fréquents. Les autres sont alors remplacer par le symbôle d'index 2. Il faut en tenir compte pour obtenir un texte lisible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88584\n",
      "['N/A', 'this', 'film', 'was', 'just', 'brilliant', 'casting', 'location', 'scenery', 'story', 'direction', \"everyone's\", 'really', 'suited', 'the', 'part', 'they', 'played', 'and', 'you', 'could', 'just', 'imagine', 'being', 'there', 'robert', 'N/A', 'is', 'an', 'amazing', 'actor', 'and', 'now', 'the', 'same', 'being', 'director', 'N/A', 'father', 'came', 'from', 'the', 'same', 'scottish', 'island', 'as', 'myself', 'so', 'i', 'loved', 'the', 'fact', 'there', 'was', 'a', 'real', 'connection', 'with', 'this', 'film', 'the', 'witty', 'remarks', 'throughout', 'the', 'film', 'were', 'great', 'it', 'was', 'just', 'brilliant', 'so', 'much', 'that', 'i', 'bought', 'the', 'film', 'as', 'soon', 'as', 'it', 'was', 'released', 'for', 'N/A', 'and', 'would', 'recommend', 'it', 'to', 'everyone', 'to', 'watch', 'and', 'the', 'fly', 'fishing', 'was', 'amazing', 'really', 'cried', 'at', 'the', 'end', 'it', 'was', 'so', 'sad', 'and', 'you', 'know', 'what', 'they', 'say', 'if', 'you', 'cry', 'at', 'a', 'film', 'it', 'must', 'have', 'been', 'good', 'and', 'this', 'definitely', 'was', 'also', 'N/A', 'to', 'the', 'two', 'little', \"boy's\", 'that', 'played', 'the', 'N/A', 'of', 'norman', 'and', 'paul', 'they', 'were', 'just', 'brilliant', 'children', 'are', 'often', 'left', 'out', 'of', 'the', 'N/A', 'list', 'i', 'think', 'because', 'the', 'stars', 'that', 'play', 'them', 'all', 'grown', 'up', 'are', 'such', 'a', 'big', 'profile', 'for', 'the', 'whole', 'film', 'but', 'these', 'children', 'are', 'amazing', 'and', 'should', 'be', 'praised', 'for', 'what', 'they', 'have', 'done', \"don't\", 'you', 'think', 'the', 'whole', 'story', 'was', 'so', 'lovely', 'because', 'it', 'was', 'true', 'and', 'was', \"someone's\", 'life', 'after', 'all', 'that', 'was', 'shared', 'with', 'us', 'all']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# à vous\n",
    "print len(wrd2idx)\n",
    "''' Les cles representent la definition du mot dans le dictionnaire\n",
    "    et les valeurs, leur representation dans les textes\n",
    "'''\n",
    "\n",
    "def rev_dict(d):\n",
    "    tmp = {}\n",
    "    for word,idt in d.iteritems():\n",
    "        tmp[str(idt+3)] = word\n",
    "        \n",
    "    return tmp\n",
    "        \n",
    "\n",
    "def tranduire_texte(t,d):\n",
    "    text_tmp = []\n",
    "    dict_tmp = rev_dict(d)\n",
    "    for mot in t:    \n",
    "        text_tmp.append(dict_tmp.get(str(mot),\"N/A\"))\n",
    "        \n",
    "    print text_tmp \n",
    "        \n",
    "        \n",
    "    \n",
    "print tranduire_texte(X_train[0],wrd2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistiques\n",
    "Nous allons maintenant faire des statistiques élémentaires sur les données. \n",
    "* écrire une fonction qui prend en paramètres *X_train* et qui retourne un dictionnaire ou par chaque pour index de mot est associé son compte observé sur toutes les données. \n",
    "* tracer la courbe  associée avec en abscisse l'index du mot et en ordonnée le nombre d'occurence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# à vous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données\n",
    "\n",
    "Pour apprendre un modèle, il est souvent utile de convertir les données dans le format attendu par l'implémentation du modèle. Dans le cas de la régression logistique, les premières expériences vont utiliser une représentation en sac binaire des textes (voir le cours). \n",
    "\n",
    "* écrire une fonction qui convertit X_train en une matrice contenant tous les exemples d'apprentissage (chaque texte sera un ligne de la matrice, soit un vecteur). \n",
    "* écrire une fonction qui fait la même chose, mais avec les comptes de mots. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# à vous"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
