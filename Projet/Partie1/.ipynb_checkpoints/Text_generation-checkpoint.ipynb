{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce TP est de construire un modèle capable d'apprendre à générer des séquences. \n",
    "Ici, nous allons nous placer au niveau du caractère: un texte est vu comme une séquence de caractères. Le modèle est un modèle récurrent qui à partir d'un historique prédit le caractère qui suit. Pour simplifier le traitement des données et réduire la compléxité du problème, l'historique sera de taille fixe (*maxlen* dans la suite). \n",
    "\n",
    "Les données d'apprentissage se présente comme une séquence de taille *maxlen* (l'entrée) et la sortie est le caractère qui suit. \n",
    "\n",
    "Lors de la génération, nous allons donné une séquence de démarrage puis demander au modèle de prédire le caractère suivant. Pour cela, le modèle va calculer la probabilité que chaque caractère soit le suivant puis nous allons échantilloner dans cette distribution. Puis nous passerons au caractère suivant. \n",
    "\n",
    "\n",
    "\n",
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "import random\n",
    "import sys\n",
    "\n",
    "lang='en'\n",
    "dataset='train'\n",
    "datad='data/tatoeba/'\n",
    "trainfile = datad+dataset+'.'+lang+'.gz'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "# chargement de tous le texte sous la forme d'une loooongue chaine de caractère\n",
    "import gzip\n",
    "fin=gzip.open(trainfile,'rb')\n",
    "text = fin.read()\n",
    "fin.close()\n",
    "\n",
    "print(type(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation des données\n",
    "\n",
    "- construire l'ensemble des caractères présents dans le texte\n",
    "- construire un dictionnaire associant chaque caractère à un index\n",
    "- construire un dictionnaire associant chaque index à son caractère\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars:  100\n",
      "{0: 'w', 1: 'h', 2: 'e', 3: 'n', 4: ' ', 5: 'a', 6: 's', 7: 'k', 8: 'd', 9: 'o', 10: 'b', 11: 'r', 12: 't', 13: 'i', 14: ',', 15: 'l', 16: 'y', 17: 'p', 18: 'u', 19: 'f', 20: 'c', 21: '.', 22: '\\n', 23: 'I', 24: \"'\", 25: 'm', 26: 'g', 27: '!', 28: '?', 29: 'J', 30: '1', 31: '8', 32: 'M', 33: '2', 34: '0', 35: '\"', 36: 'v', 37: 'j', 38: '\\xe2', 39: '\\x82', 40: '\\xac', 41: '3', 42: 'Y', 43: 'x', 44: 'A', 45: '6', 46: 'T', 47: 'z', 48: 'V', 49: 'W', 50: 'S', 51: 'E', 52: 'F', 53: 'q', 54: 'H', 55: '-', 56: 'R', 57: '9', 58: '5', 59: 'N', 60: 'P', 61: ';', 62: 'B', 63: ':', 64: 'D', 65: 'C', 66: 'G', 67: '4', 68: '%', 69: 'L', 70: 'K', 71: 'U', 72: '7', 73: '\\xc2', 74: '\\xb0', 75: '\\xc3', 76: '\\xa9', 77: '(', 78: ')', 79: '$', 80: 'O', 81: '&', 82: 'Q', 83: 'Z', 84: 'X', 85: '/', 86: '\\xaf', 87: '#', 88: '\\xa8', 89: '[', 90: ']', 91: '\\xab', 92: '\\xbb', 93: '\\xb6', 94: '\\x9f', 95: '\\xbc', 96: '\\xad', 97: '\\xb4', 98: '\\xa2', 99: '+'}\n",
      "{'\\x9f': 94, ' ': 4, '$': 79, '(': 77, '\\xab': 91, ',': 14, '\\xaf': 86, '0': 34, '4': 67, '8': 31, '\\xbb': 92, '\\xc3': 75, 'D': 64, 'H': 54, 'L': 69, 'P': 60, 'T': 46, 'X': 84, 'd': 8, 'h': 1, 'l': 15, 'p': 17, 't': 12, 'x': 43, '#': 87, \"'\": 24, '\\xa8': 88, '+': 99, '\\xac': 40, '/': 85, '\\xb0': 74, '3': 41, '\\xb4': 97, '7': 72, ';': 61, '\\xbc': 95, '?': 28, 'C': 65, 'G': 66, 'K': 70, 'O': 80, 'S': 50, 'W': 49, '[': 89, 'c': 20, 'g': 26, 'k': 7, 'o': 9, 's': 6, 'w': 0, '\\n': 22, '\"': 35, '&': 81, '\\xa9': 76, '\\xad': 96, '.': 21, '2': 33, '6': 45, ':': 63, 'B': 62, 'F': 52, 'J': 29, 'N': 59, 'R': 56, 'V': 48, 'Z': 83, 'b': 10, 'f': 19, 'j': 37, 'n': 3, 'r': 11, 'v': 36, 'z': 47, '\\x82': 39, '!': 27, '\\xa2': 98, '%': 68, ')': 78, '-': 55, '1': 30, '5': 58, '\\xb6': 93, '9': 57, 'A': 44, '\\xc2': 73, 'E': 51, 'I': 23, 'M': 32, 'Q': 82, 'U': 71, 'Y': 42, ']': 90, 'a': 5, '\\xe2': 38, 'e': 2, 'i': 13, 'm': 25, 'q': 53, 'u': 18, 'y': 16}\n"
     ]
    }
   ],
   "source": [
    "# à vous de jouer\n",
    "chars = None\n",
    "char_indices = None\n",
    "indices_char = None\n",
    "\n",
    "def count_dif_char(string):\n",
    "    tmp = []\n",
    "    for c in string:\n",
    "        if c not in tmp:\n",
    "            tmp.append(c)\n",
    "    return tmp\n",
    "\n",
    "def create_dict(l):\n",
    "    tmp = {}\n",
    "    cpt = 0    \n",
    "    for e in l:\n",
    "        tmp[cpt] = e\n",
    "        cpt+=1\n",
    "    return tmp\n",
    "\n",
    "def rev_dict(d):\n",
    "    tmp = {}\n",
    "    for word,idt in d.iteritems():\n",
    "        tmp[idt] = word\n",
    "\n",
    "    return tmp\n",
    "\n",
    "chars = count_dif_char(text)\n",
    "print'total chars: ', len(chars) # on doit trouver 100\n",
    "\n",
    "\n",
    "indices_char = create_dict(chars)\n",
    "print(indices_char)\n",
    "\n",
    "char_indices = rev_dict(indices_char)\n",
    "print(char_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis nous allons créer deux listes : \n",
    "- sentences qui contient les historiques (chaine de caractères de taille *maxlen*)\n",
    "- next_chars qui contient le caractère chaque historique\n",
    "\n",
    "Par exemple \n",
    "l'historique 'when he as' sera associé à  'k'. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 10 # the size of the context\n",
    "step = 1    # move from step\n",
    "sentences = []\n",
    "next_chars = []\n",
    "# à vous de jouer\n",
    "\"\"\"\n",
    "    Generaliser ce qui suit:\n",
    "    sentences.append(text[0:10])\n",
    "    next_chars.append(text[10])\n",
    "    print sentences[0],\" -> \", next_chars[0]\n",
    "\"\"\"\n",
    "def build_history(string):\n",
    "    history = []\n",
    "    char_next = []\n",
    "    size = len(text)\n",
    "    for i in range(size-maxlen-1):        \n",
    "        sentences.append(text[i:i+maxlen])  \n",
    "        next_chars.append(text[maxlen+i])\n",
    "\n",
    "build_history(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nb sequences:', 1668883)\n",
      "('when he as', 'k')\n",
      "('hen he ask', 'e')\n",
      "('en he aske', 'd')\n",
      "('n he asked', ' ')\n"
     ]
    }
   ],
   "source": [
    "print('nb sequences:', len(sentences))\n",
    "for i in range(4):\n",
    "    print (sentences[i], next_chars[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sous-échantillonage des données\n",
    "Afin de réduire le temps de calcul nous allons prendre qu'une sous partie des données d'apprentissage que nous allons vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 100000)\n",
      "('vacation t', 'h')\n",
      "('a doctor t', 'o')\n",
      "('tarted sai', 'l')\n",
      "(\"\\nthat's a \", 'g')\n"
     ]
    }
   ],
   "source": [
    "# subsampling\n",
    "import random\n",
    "nbSamples=100000\n",
    "ids = range(nbSamples) \n",
    "random.shuffle(ids) # mélange le tout\n",
    "xsentences = list()\n",
    "xnext_chars = list()\n",
    "for i in ids:\n",
    "    xsentences.append(sentences[i])\n",
    "    xnext_chars.append(next_chars[i])\n",
    "print (len(xnext_chars), len(xsentences))\n",
    "\n",
    "for i in range(4):\n",
    "    print (xsentences[i], xnext_chars[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mettons tout dans des matrices \n",
    "\n",
    "Pour l'apprentissage du modèle les données doivent être mis dans des matrices. Pour cela les caractères sont remplacés par les index correspondants. \n",
    "\n",
    "** ATTENTION: ** \n",
    "- Le modèle Sequential admet des entrées qui ont toutes la même taille, ici c'est le cas par construction, mais sinon il faut faire du padding\n",
    "- Contrairement au TP précédent, nous allons utiliser un *layer* de type *Embedding* pour l'entrée. Ainsi une séquence de caractère sera une séquence d'index et l'*Embedding* se charge de créer un vecteur par caractère et l'associé via son index. \n",
    "- Pour la sortie du modèle, ce n'est plus de la classification binaire. Il y a 99 sorties possibles. Nous allons utiliser une couche de sortie *Softmax* \n",
    "- Les données de sorties doivent alors avoir une forme particulière (voir le code ci-dessous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "((100000, 10), (100000, 100))\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "X = np.zeros((len(xsentences),maxlen), dtype=np.int32)\n",
    "y = np.zeros((len(xsentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(xsentences):\n",
    "    for  t,char in enumerate(sentence):\n",
    "        X[i,t] = char_indices[char]\n",
    "    y[i, char_indices[xnext_chars[i]]] = 1\n",
    "    \n",
    "print (X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du modèle\n",
    "\n",
    "Il sera composé : \n",
    "- d'une couche Embedding\n",
    "- un modèle recurrent qui prendra en entrée les embeddings\n",
    "- puis une sortie softmax\n",
    "Soit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model Built !\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sequantial\n",
    "    1er  couche --> Embending (size = nbChars*128)\n",
    "    2eme couche --> SimpleRNN (size = 128)\n",
    "    3eme couche --> Dense(prends la derniere couche du réseau réccurent qui servira a prédire le caractère suivant\n",
    "                            size = 128 * |nbChars|)\n",
    "    4eme couche --> SorftMax\n",
    "\"\"\"\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(chars),128))\n",
    "model.add(SimpleRNN(256))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "print('Model Built !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100000/100000 [==============================] - 237s - loss: 3.6254   \n",
      "Epoch 2/3\n",
      "100000/100000 [==============================] - 237s - loss: 2.3329   \n",
      "Epoch 3/3\n",
      "100000/100000 [==============================] - 238s - loss: 2.1313   \n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=256, nb_epoch=3)\n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération \n",
    "Une fois le modèle appris, il faut générer une séquence. Pour cela la fonction suivante est donnée: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "('----- diversity:', 0.1)\n",
      "----- Generating with seed: \"when he as\"\n",
      "when he as the cant to my can juco to my can to Cear to my can juco to my can to Cear to my can juco tour to my can juco tour to my can juco tour to my can juco tour to my can ex , I could to my can juco tour t()\n",
      "()\n",
      "('----- diversity:', 0.2)\n",
      "----- Generating with seed: \"when he as\"\n",
      "when he as the cour to my can juco tour to my can expeat to my can juct to list to my a the my a lou can just to Cou the cour to my can the cant to the cour tad joun to my can the my are cant to my can juco tou()\n",
      "()\n",
      "('----- diversity:', 1)\n",
      "----- Generating with seed: \"when he as\"\n",
      "when he as the frer caskeam tybe myon is dour ene to my jost wle tear wask touble to the reak .\n",
      "I could to che cant cagll yy hiccly .\n",
      "I havort have cmelmes werorted to loubjur ?\n",
      "I clead ste trou a mex he arases()\n"
     ]
    }
   ],
   "source": [
    "start_index = 0#random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "#for diversity in [0.1, 0.2, 0.5, 1.0, 1.2]:\n",
    "for diversity in [0.1,0.2,1]: \n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "        # sentence keeps the last \"max_len\" chars \n",
    "        # init : \n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(sentence)\n",
    "        for i in range(200):\n",
    "            x = np.zeros((1, maxlen), dtype=np.int16)\n",
    "            # fill x with sentence\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t]= char_indices[char]\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            # move the sliding window \n",
    "            sentence = sentence[1:] + next_char\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "** à faire ensuite : ** \n",
    "- Regarder les différents *optimizers* disponibles.\n",
    "- Faites varier la taille des embeddings,\n",
    "- puis la taille de la couche cachée du réseau récurrent\n",
    "- Le type de réseau récurrent (essayer LSTM  et GRU à la place de SimpleRNN, et regarder les résultats et le temps de calcul).\n",
    "- Augmenter le nombre d'époque d'apprentissage et regarder au passage comment la fonction objectif évolue. \n",
    "- On peut ajouter des données de validations pour voir ce qui se passe également. \n",
    "- Augmenter la quantité de données. \n",
    "- Pour la génération essayer différents démarrages. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
