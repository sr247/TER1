{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/python2.7\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "import tarfile as tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Parse:\n",
    "    def __init__(self): pass\n",
    "        \n",
    "    \n",
    "def infoTar(t):\n",
    "    for finfo in t.getmembers():\n",
    "        print('%s a une taille de %d octets' % (finfo.name, finfo.size), '')\n",
    "        if finfo.isdir():\n",
    "            print(' et est un r√©pertoire')\n",
    "        elif finfo.isfile():\n",
    "            print(' et est un fichier normal')\n",
    "\n",
    "            \n",
    "def extractFile(t, src, dest):\n",
    "    fichier = open(dest,'wb')\n",
    "    extr = t.extractfile(src)\n",
    "    # for line in extr:\n",
    "    # lines = extr.readline()\n",
    "    fichier.write(extr.read())\n",
    "    fichier.close()    \n",
    "    extr.close()    \n",
    "\n",
    "\n",
    "def describ():\n",
    "    print ( \"Parsing ...\\nExtracting data ...\")\n",
    "    print ( \"Fichier : %s\" % fname)\n",
    "    print ( \"I - Taille\")\n",
    "    print ( \"\\tNombre de phrases : %d\" % nb_phrases)\n",
    "    print ( \"\\tNombre d'exemples d'aprentissages : %d\" % nb_exemples)\n",
    "    print (\"\\tNombre de caracteres moyen par phrases : %d\" % nb_caractere_moyen)\n",
    "    print (\"II - Vocabulaire\")\n",
    "    print (\"\\tNombre de caractere dictincts totals : %d\" % nb_caractere_distinc) \n",
    "    print (\"\\tNombre de mots dictincts totals : %d\" % nb_mot_disctinc) \n",
    "    \n",
    "def parser(name):\n",
    "    fichier = open(name,'r')\n",
    "    tmp = {}\n",
    "    exemple = []\n",
    "    i = 0\n",
    "    k = 0    \n",
    "    for line in fichier:  \n",
    "        exemple.append(line)\n",
    "        i+=1\n",
    "        if \"?\" in line:\n",
    "            tmp[k] = []\n",
    "            for e in exemple:\n",
    "                tmp[k].append(e)\n",
    "            k+=1\n",
    "\n",
    "    return tmp,i,k\n",
    "    \n",
    "# def classer(): pass\n",
    "def compterCaractere(data):\n",
    "    nb_char = 0\n",
    "    nb_char_moy = []\n",
    "    list_car = []\n",
    "    list_mot = []\n",
    "    for key in data:\n",
    "        for liste in data[key]:\n",
    "            for e in liste.split(\" \"):\n",
    "                if e not in list_mot:\n",
    "                    list_mot.append(e)\n",
    "            for c in liste:\n",
    "                if c != '\\n':\n",
    "                    nb_char += 1\n",
    "                if c not in list_car:\n",
    "                    list_car.append(c)\n",
    "            nb_char_moy.append(nb_char)\n",
    "            nb_char = 0\n",
    "    for e in nb_char_moy:\n",
    "        nb_char += e\n",
    "    return len(list_car), nb_char/len(nb_char_moy), len(list_mot), list_mot\n",
    "\n",
    "def compareVoc(a,b):\n",
    "    Sa = set(a)\n",
    "    Sb = set(b)\n",
    "    \n",
    "    print(Sa)\n",
    "    print(Sb)\n",
    "        \n",
    "bAbitask = tar.open('tasks_1-20_v1-2.tar.gz', 'r')\n",
    "fname = \"trainset.txt\"\n",
    "\n",
    "\n",
    "dataTrain = {}\n",
    "dataTest = {}\n",
    "nb_phrases = 0\n",
    "nb_exemples = 0\n",
    "nb_caractere_distinc = 0\n",
    "nb_caractere_moyen = 0\n",
    "nb_mot_disctinc = 0\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ...\n",
      "Extracting data ...\n",
      "Fichier : trainset.txt\n",
      "I - Taille\n",
      "\tNombre de phrases : 3000\n",
      "\tNombre d'exemples d'aprentissages : 1000\n",
      "\tNombre de caracteres moyen par phrases : 30\n",
      "II - Vocabulaire\n",
      "\tNombre de caractere dictincts totals : 42\n",
      "\tNombre de mots dictincts totals : 98\n",
      "Parsing ...\n",
      "Extracting data ...\n",
      "Fichier : testset.txt\n",
      "I - Taille\n",
      "\tNombre de phrases : 3000\n",
      "\tNombre d'exemples d'aprentissages : 1000\n",
      "\tNombre de caracteres moyen par phrases : 30\n",
      "II - Vocabulaire\n",
      "\tNombre de caractere dictincts totals : 42\n",
      "\tNombre de mots dictincts totals : 98\n",
      "{'office.\\n', 'Sandra', '\\tbedroom\\t4\\n', '\\tgarden\\t7\\n', 'Mary', '\\tbathroom\\t1\\n', '8', '\\thallway\\t13\\n', '\\tkitchen\\t4\\n', '11', '4', 'bedroom.\\n', '\\tbathroom\\t13\\n', 'Where', '\\thallway\\t10\\n', '\\tgarden\\t4\\n', 'back', '\\toffice\\t11\\n', 'travelled', '\\toffice\\t8\\n', '9', '\\tgarden\\t8\\n', '5', '\\tkitchen\\t2\\n', '\\thallway\\t4\\n', '\\tgarden\\t5\\n', '13', '\\tbedroom\\t2\\n', 'moved', '7', '\\toffice\\t10\\n', '\\thallway\\t7\\n', '\\thallway\\t11\\n', '\\tbathroom\\t11\\n', '15', '\\tgarden\\t13\\n', '\\toffice\\t13\\n', '\\tkitchen\\t8\\n', 'Daniel', '\\tgarden\\t2\\n', '\\thallway\\t5\\n', '\\tkitchen\\t1\\n', '\\tbedroom\\t1\\n', '\\tbedroom\\t5\\n', '\\tkitchen\\t11\\n', '\\tkitchen\\t5\\n', '\\tgarden\\t10\\n', '\\tbedroom\\t14\\n', '6', '\\tkitchen\\t13\\n', '\\tbedroom\\t11\\n', 'the', '\\toffice\\t14\\n', 'garden.\\n', 'Sandra?', '\\toffice\\t7\\n', '\\tgarden\\t1\\n', '14', '\\tbedroom\\t8\\n', '\\thallway\\t1\\n', 'John?', '3', '2', '\\tkitchen\\t10\\n', '\\thallway\\t8\\n', '\\toffice\\t4\\n', '\\tbedroom\\t7\\n', '\\tkitchen\\t14\\n', 'bathroom.\\n', '\\tkitchen\\t7\\n', '\\tbathroom\\t5\\n', '\\tgarden\\t11\\n', '12', '10', '\\tbedroom\\t13\\n', '\\toffice\\t5\\n', 'went', '\\tbathroom\\t4\\n', 'Daniel?', '\\tgarden\\t14\\n', 'Mary?', '\\tbathroom\\t2\\n', '\\tbathroom\\t14\\n', '\\tbathroom\\t10\\n', 'to', '\\tbedroom\\t10\\n', 'journeyed', 'is', '\\tbathroom\\t8\\n', 'John', 'kitchen.\\n', '\\thallway\\t2\\n', '\\toffice\\t1\\n', '\\tbathroom\\t7\\n', '\\thallway\\t14\\n', '\\toffice\\t2\\n', '1', 'hallway.\\n'}\n",
      "{'office.\\n', 'Sandra', '\\tbedroom\\t4\\n', 'Mary', '\\tgarden\\t7\\n', '\\tbathroom\\t1\\n', '8', '\\tkitchen\\t4\\n', '\\thallway\\t13\\n', '11', '4', 'bedroom.\\n', '\\tbathroom\\t13\\n', 'Where', '\\thallway\\t10\\n', '\\tgarden\\t4\\n', 'back', '\\toffice\\t11\\n', 'travelled', '\\toffice\\t8\\n', '9', '\\tgarden\\t8\\n', '5', '\\tkitchen\\t2\\n', '\\thallway\\t4\\n', '\\tgarden\\t5\\n', '13', '\\tbedroom\\t2\\n', 'moved', '7', '\\toffice\\t10\\n', '\\thallway\\t7\\n', '\\thallway\\t11\\n', '\\tbathroom\\t11\\n', '15', '\\tgarden\\t13\\n', '\\toffice\\t13\\n', '\\tkitchen\\t8\\n', 'Daniel', '\\tgarden\\t2\\n', '\\thallway\\t5\\n', '\\tkitchen\\t1\\n', '\\tbedroom\\t1\\n', '\\tkitchen\\t11\\n', '\\tbedroom\\t5\\n', '\\tkitchen\\t5\\n', '\\tgarden\\t10\\n', '\\tbedroom\\t14\\n', '6', '\\tkitchen\\t13\\n', '\\tbedroom\\t11\\n', 'the', '\\toffice\\t14\\n', 'garden.\\n', 'Sandra?', '\\toffice\\t7\\n', '\\tgarden\\t1\\n', '14', '\\tbedroom\\t8\\n', '\\thallway\\t1\\n', 'John?', '3', '2', '\\tkitchen\\t10\\n', '\\thallway\\t8\\n', '\\toffice\\t4\\n', '\\tbedroom\\t7\\n', '\\tkitchen\\t14\\n', 'bathroom.\\n', '\\tkitchen\\t7\\n', '\\tbathroom\\t5\\n', '\\tgarden\\t11\\n', '12', '10', '\\tbedroom\\t13\\n', '\\toffice\\t5\\n', 'went', '\\tbathroom\\t4\\n', 'Daniel?', '\\tgarden\\t14\\n', 'Mary?', '\\tbathroom\\t2\\n', '\\tbathroom\\t14\\n', '\\tbathroom\\t10\\n', 'to', '\\tbedroom\\t10\\n', 'journeyed', 'is', '\\tbathroom\\t8\\n', 'John', 'kitchen.\\n', '\\thallway\\t2\\n', '\\toffice\\t1\\n', '\\tbathroom\\t7\\n', '\\thallway\\t14\\n', '\\toffice\\t2\\n', '1', 'hallway.\\n'}\n"
     ]
    }
   ],
   "source": [
    "extractFile(bAbitask, \"tasks_1-20_v1-2/en/qa1_single-supporting-fact_train.txt\", fname)\n",
    "dataTrain,nb_phrases,nb_exemples = parser(fname)\n",
    "nb_caractere_distinc,nb_caractere_moyen,nb_mot_disctinc,vocab_train = compterCaractere(dataTrain)\n",
    "describ()\n",
    "\n",
    "fname = \"testset.txt\"\n",
    "\n",
    "extractFile(bAbitask, \"tasks_1-20_v1-2/en/qa1_single-supporting-fact_test.txt\", fname)\n",
    "dataTest,nb_phrases,nb_exemples = parser(fname)\n",
    "nb_caractere_distinc,nb_caractere_moyen,nb_mot_disctinc,vocab_test = compterCaractere(dataTest)\n",
    "describ()\n",
    "compareVoc(vocab_train,vocab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bAbitask.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
