{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN / Embed / Sent / Query = <class 'keras.layers.recurrent.LSTM'>, 50, 100, 100\n",
      "66\n",
      "vocab = [u'.', u'?', u'Daniel', u'John', u'Mary', u'Sandra', u'Where', u'back', u'bathroom', u'bedroom', u'garden', u'hallway', u'is', u'journeyed', u'kitchen', u'moved', u'office', u'the', u'to', u'travelled', u'went']\n",
      "X.shape = (1000, 66)\n",
      "Xq.shape = (1000, 4)\n",
      "Y.shape = (1000, 22)\n",
      "story_maxlen, query_maxlen = 66, 4\n"
     ]
    }
   ],
   "source": [
    "'''Trains two recurrent neural networks based upon a story and a question.\n",
    "The resulting merged vector is then queried to answer a range of bAbI tasks.\n",
    "The results are comparable to those for an LSTM model provided in Weston et al.:\n",
    "\"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\"\n",
    "http://arxiv.org/abs/1502.05698\n",
    "Task Number                  | FB LSTM Baseline | Keras QA\n",
    "---                          | ---              | ---\n",
    "QA1 - Single Supporting Fact | 50               | 100.0\n",
    "QA2 - Two Supporting Facts   | 20               | 50.0\n",
    "QA3 - Three Supporting Facts | 20               | 20.5\n",
    "QA4 - Two Arg. Relations     | 61               | 62.9\n",
    "QA5 - Three Arg. Relations   | 70               | 61.9\n",
    "QA6 - Yes/No Questions       | 48               | 50.7\n",
    "QA7 - Counting               | 49               | 78.9\n",
    "QA8 - Lists/Sets             | 45               | 77.2\n",
    "QA9 - Simple Negation        | 64               | 64.0\n",
    "QA10 - Indefinite Knowledge  | 44               | 47.7\n",
    "QA11 - Basic Coreference     | 72               | 74.9\n",
    "QA12 - Conjunction           | 74               | 76.4\n",
    "QA13 - Compound Coreference  | 94               | 94.4\n",
    "QA14 - Time Reasoning        | 27               | 34.8\n",
    "QA15 - Basic Deduction       | 21               | 32.4\n",
    "QA16 - Basic Induction       | 23               | 50.6\n",
    "QA17 - Positional Reasoning  | 51               | 49.1\n",
    "QA18 - Size Reasoning        | 52               | 90.8\n",
    "QA19 - Path Finding          | 8                | 9.0\n",
    "QA20 - Agent's Motivations   | 91               | 90.7\n",
    "For the resources related to the bAbI project, refer to:\n",
    "https://research.facebook.com/researchers/1543934539189348\n",
    "Notes:\n",
    "- With default word, sentence, and query vector sizes, the GRU model achieves:\n",
    "  - 100% test accuracy on QA1 in 20 epochs (2 seconds per epoch on CPU)\n",
    "  - 50% test accuracy on QA2 in 20 epochs (16 seconds per epoch on CPU)\n",
    "In comparison, the Facebook paper achieves 50% and 20% for the LSTM baseline.\n",
    "- The task does not traditionally parse the question separately. This likely\n",
    "improves accuracy and is a good example of merging two RNNs.\n",
    "- The word vector embeddings are not shared between the story and question RNNs.\n",
    "- See how the accuracy changes given 10,000 training samples (en-10k) instead\n",
    "of only 1000. 1000 was used in order to be comparable to the original paper.\n",
    "- Experiment with GRU, LSTM, and JZS1-3 as they give subtly different results.\n",
    "- The length and noise (i.e. 'useless' story components) impact the ability for\n",
    "LSTMs / GRUs to provide the correct answer. Given only the supporting facts,\n",
    "these RNNs can achieve 100% accuracy on many tasks. Memory networks and neural\n",
    "networks that use attentional processes can efficiently search through this\n",
    "noise to find the relevant statements, improving performance substantially.\n",
    "This becomes especially obvious on QA2 and QA3, both far longer than QA1.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from functools import reduce\n",
    "import re\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Merge, Dropout, RepeatVector\n",
    "from keras.layers import recurrent\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def tokenize(sent):\n",
    "    '''Return the tokens of a sentence including punctuation.\n",
    "    >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
    "    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
    "    '''\n",
    "    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n",
    "\n",
    "\n",
    "def parse_stories(lines, only_supporting=False):\n",
    "    '''Parse stories provided in the bAbi tasks format\n",
    "    If only_supporting is true, only the sentences that support the answer are kept.\n",
    "    '''\n",
    "    data = []\n",
    "    story = []\n",
    "    count = 0\n",
    "    for line in lines:\n",
    "        count += 1\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            substory = None\n",
    "            if only_supporting:\n",
    "                # Only select the relMAated substory\n",
    "                supporting = map(int, supporting.split())\n",
    "                substory = [story[i - 1] for i in supporting]\n",
    "            else:\n",
    "                # Provide all the substories\n",
    "                substory = [x for x in story if x]  \n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_stories(f, only_supporting=False, max_length=None):\n",
    "    '''Given a file name, read the file, retrieve the stories, and then convert the sentences into a single story.\n",
    "    If max_length is supplied, any stories longer than max_length tokens will be discarded.\n",
    "    '''\n",
    "    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    data = [(flatten(story), q, answer) for story, q, answer in data if not max_length or len(flatten(story)) < max_length]\n",
    "    return data\n",
    "\n",
    "\n",
    "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
    "    X = []\n",
    "    Xq = []\n",
    "    Y = []\n",
    "    for story, query, answer in data:\n",
    "        x = [word_idx[w] for w in story]\n",
    "        xq = [word_idx[w] for w in query]\n",
    "        y = np.zeros(len(word_idx) + 1)  # let's not forget that index 0 is reserved\n",
    "        y[word_idx[answer]] = 1\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "    return pad_sequences(X, maxlen=story_maxlen), pad_sequences(Xq, maxlen=query_maxlen), np.array(Y)\n",
    "\n",
    "RNN = recurrent.LSTM\n",
    "EMBED_HIDDEN_SIZE = 50\n",
    "SENT_HIDDEN_SIZE = 100\n",
    "QUERY_HIDDEN_SIZE = 100\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN, EMBED_HIDDEN_SIZE, SENT_HIDDEN_SIZE, QUERY_HIDDEN_SIZE))\n",
    "\n",
    "try:\n",
    "    path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\n",
    "except:\n",
    "    print('Error downloading dataset, please download it manually:\\n'\n",
    "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\\n'\n",
    "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
    "    raise\n",
    "tar = tarfile.open(path)\n",
    "# Default QA1 with 1000 samples\n",
    "challenge = 'tasks_1-20_v1-2/en/qa1_single-supporting-fact_{}.txt'\n",
    "# challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt'\n",
    "# QA1 with 10,000 samples\n",
    "# challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt'\n",
    "# QA2 with 1000 samples\n",
    "# challenge = 'tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt'\n",
    "# QA2 with 10,000 samples\n",
    "# challenge = 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt'\n",
    "train = get_stories(tar.extractfile(challenge.format('train')))\n",
    "test = get_stories(tar.extractfile(challenge.format('test')))\n",
    "\n",
    "vocab = sorted(reduce(lambda x, y: x | y, (set(story + q + [answer]) for story, q, answer in train + test)))\n",
    "# Reserve 0 for masking via pad_sequences\n",
    "vocab_size = len(vocab) + 1\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "story_maxlen = max(map(len, (x for x, _, _ in train + test)))\n",
    "query_maxlen = max(map(len, (x for _, x, _ in train + test)))\n",
    "\n",
    "X, Xq, Y    = vectorize_stories(train, word_idx, story_maxlen, query_maxlen)\n",
    "tX, tXq, tY = vectorize_stories( test, word_idx, story_maxlen, query_maxlen)\n",
    "\n",
    "print(len(X[0]))\n",
    "print('vocab = {}'.format(vocab))\n",
    "print('X.shape = {}'.format(X.shape))\n",
    "print('Xq.shape = {}'.format(Xq.shape))\n",
    "print('Y.shape = {}'.format(Y.shape))\n",
    "print('story_maxlen, query_maxlen = {}, {}'.format(story_maxlen, query_maxlen))\n",
    "\n",
    "# supportingFacts false\n",
    "# 10 k \n",
    "# 40 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Training\n",
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/5\n",
      "950/950 [==============================] - 5s - loss: 2.5918 - acc: 0.1495 - val_loss: 2.0151 - val_acc: 0.2200\n",
      "Epoch 2/5\n",
      "950/950 [==============================] - 5s - loss: 1.9959 - acc: 0.1811 - val_loss: 1.8215 - val_acc: 0.2200\n",
      "Epoch 3/5\n",
      "950/950 [==============================] - 5s - loss: 1.9256 - acc: 0.1474 - val_loss: 1.7651 - val_acc: 0.2800\n",
      "Epoch 4/5\n",
      "950/950 [==============================] - 5s - loss: 1.9008 - acc: 0.1653 - val_loss: 1.7740 - val_acc: 0.2000\n",
      "Epoch 5/5\n",
      "950/950 [==============================] - 5s - loss: 1.8401 - acc: 0.2084 - val_loss: 1.7484 - val_acc: 0.3200\n",
      "1000/1000 [==============================] - 1s     \n",
      "Test loss / test accuracy = 1.7523 / 0.3220\n",
      "acc: 32.20%\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "qrnn = Sequential()\n",
    "qrnn.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE,\n",
    "                   input_length=query_maxlen))\n",
    "\n",
    "qrnn.add(Dropout(0.3))\n",
    "qrnn.add(RNN(EMBED_HIDDEN_SIZE, return_sequences=False))\n",
    "\n",
    "qrnn.add(RepeatVector(story_maxlen))\n",
    "\n",
    "sentrnn = Sequential()\n",
    "sentrnn.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE,\n",
    "                      input_length=story_maxlen))\n",
    "sentrnn.add(Dropout(0.3))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([sentrnn, qrnn], mode='sum')) # Merge est deprecier il faudra utiliser model.add([sentrnn, qrnn])\n",
    "                                              # ou model.concatenate([sentrnn, qrnn])\n",
    "model.add(RNN(EMBED_HIDDEN_SIZE, return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Training')\n",
    "history = model.fit([X, Xq], Y, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, validation_split=0.05)\n",
    "loss, acc = model.evaluate([tX, tXq], tY, batch_size=BATCH_SIZE)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], acc*100))\n",
    "best = acc * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques dates\n",
    "\n",
    "Avant le 21/04 :\n",
    "¤ Remise du rapport \n",
    "   - Entre 10 et 20 pages\n",
    "   - Pas de code dans le rapport\n",
    "   I: Introduction  (  (3))  (1-2pages)\n",
    "   - Court\n",
    "   - Résumer la tache effectuer par le RN (spécificités, votre approche, le plan)\n",
    "   - Présenter l'état de l'art (ce qui a déja été fait) et si on s'en est inspiré\n",
    "   II: Les données ( ensuite decrire les données (2)) (2 pages max)\n",
    "   - Décrire les entrées/sorties ( nombre de taches abordées)\n",
    "   - Statistique:\n",
    "       - Taille des données train/test\n",
    "       - Vocabulaire\n",
    "       - Répartition classe\n",
    "       - Filtrage / selection des données\n",
    "   III: Le modéle ( Commencer par cette partie  (1) )   (5-6 pages)\n",
    "   - Définir le modèle ( faire une figure illustrer)\n",
    "   - Résultats/accuracy/courbe d'apprentissage (nombre d'époques, temps total, stratégie d'apprentissage utilisée)\n",
    "       -  \n",
    "   - Expliquer les coubres/diagrammes/tableaux\n",
    "   \n",
    "   IV: Conclusion (1 page)\n",
    "   - Résumer de ce qui a été fait, et ce qui reste à faire, comment on pourrait le faire \n",
    "   \n",
    "   Exemple bAbi task: Monde clos vocabulaire générer et fixes\n",
    "   Important donner des exemples : \n",
    "Mercredi 26/04,  Vendredi 28/04,   Mardi 02/05\n",
    "- Soutenance TER ( date encore à déterminer)\n",
    "  20 minutes exposé/questions\n",
    " \n",
    " \n",
    " \n",
    " A rendre Rapport + code -> archive\n",
    " Rapport: nom.pdf\n",
    " Archive: nom.tgz|zip|rar\n",
    " \n",
    " A envoyer à l'adresse:\n",
    " allauzen@limsi.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_8 (Embedding)          (None, 66, 50)        1100                                         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 66, 50)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)          (None, 4, 50)         1100                                         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 4, 50)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                    (None, 50)            20200                                        \n",
      "____________________________________________________________________________________________________\n",
      "repeatvector_4 (RepeatVector)    (None, 66, 50)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                    (None, 50)            20200       merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 50)            0           lstm_8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 22)            1122        dropout_12[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 43,722\n",
      "Trainable params: 43,722\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "{'verbose': 1, 'nb_epoch': 5, 'batch_size': 32, 'metrics': ['loss', 'acc', 'val_loss', 'val_acc'], 'nb_sample': 950, 'do_validation': True}\n",
      "<type 'list'>\n",
      "<type 'list'>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAEZCAYAAAC3qQ2zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcVNWZ//HP0+wIjSCCBhBFjQuiKBFXtNEwgBtmIgqK\noDEOiWP0pyaDk4kRxjgTJ4sGExONKKsgBEElLoikxRgFVBSURjAoArLJKkuzdD+/P85tKKq7oZvu\nrltV/X2/XvXqqrr3Vj19ofqp85xzzzF3R0RERNJXTtwBiIiIyIEpWYuIiKQ5JWsREZE0p2QtIiKS\n5pSsRURE0pyStYiISJpTshaRtGVm7c2s2MwO+rfKzAaZ2ZtVfR2RdKT/uCJSLczsczMrNLMWSc9/\nECXKYw7xpSszGcSB9tWkEpKxlKxFpLo48BnQv+QJMzsNaIgSpUiVKFmLSHUaAwxKeDwIGJW4g5nl\nmtloM1trZp+Z2X8lbMsxs1+b2Toz+xS4vIxjnzSzL81suZk9YGZWwdgMuMXMVka3uxNe92wz+4eZ\nbYy2PWpmdRO2P2xma8xsU1QpODV6vn4U7zIzW2Vmj5lZg4qeLJGKUrIWker0DtDUzE6K+oevBcYS\nEmWJ3wNNgWOBPGCgmd0cbfs34DLgDOBbwDVJrz8a2AV0AM4EegDfr0R8ecDxQE/gXjO7JHq+CPh/\nQAvgPOAS4DYAM/sX4ELgBHc/HLgOWB8d93/ACcDp0c82wM8rEY9IhShZi0h1K2ld9wAWAV+WbEhI\n4Pe6+3Z3Xwb8Brgx2qUv8Ii7f+num4D/TTi2NdALuMvdC939K+AREsruFTA0OvYj4OmSY939fXef\n48EXwBPAxdExuwlfLk41M3P3T9x9TbTt+1E8m919G/DLSsYjUiF1D76LiEiljAVmAccRWsKJWgL1\ngC8SnltGaJECfANYnrStxDHRsauiyrdFt8TXOhAHViS99mkAZnYi8FtCa74R4W/jewDu/jcz+z3w\nB6CdmU0Bfhzt1xh4L6ESn8P+VQSRanHAlnWjRo1Wm5nrduBbo0aNVqfqH0wk3UUt08+A3sBzSZu/\nIrRU2yc81x5YGd1fBbRL2lZiOVAIHOHuLdy9ubsf7u6nVyK8xNc+hn2t/j8CBcDxUan7v0hIuu7+\ne3f/FtAROAn4SfS7bAc6RvG0iOJpVol4RCrkgMm6sLCwtbuj24FvhYWFrVP1DyaSIb4HXOLuOxKf\ndPdiYCLwoJk1MbP2wF2E0jnRtjvMrI2ZNQeGJBy7GpgOPGxmTS3oYGYXVTAmA+4zs0Zm1hG4GZgQ\nbWsKbHH37WZ2MvDDvQeZfcvMukYDznYQvjAUeVhf+M/AI2Z2ZLRvm6iPW6Raqc9aRKrL3suz3P0z\nd3+/rG3AHYQW6VJCuXysuz8dbfsz8CrwIfAuMDnpPQYC9YGFwAZgEnBUJeJ7A/gUeA34P3d/Pdr2\nY+AGM9sCPM6+JA6QG8W1gVAx+Ar4dbRtSPR675jZJsKXiW9WMB6RCrPw5bCcjWZ+oO0SmBnurn4q\nERGpEWpZi4iIpDkl60hxcTFNmzZlxYoVB99ZREQkhTI2WTdt2pTc3Fxyc3OpU6cOjRs33vvc+PHj\nK/16OTk5fP3117Rt27YGohURETl0WdFn3aFDB0aMGEH37t3L3aeoqIg6derUyPurz1pERGpSxras\nE5VcQpXovvvuo1+/flx//fU0a9aMcePG8c4773DeeefRvHlz2rRpw5133klRUREQknlOTg5ffBHm\nV7jxxhu58847ueyyy8jNzeWCCy5g2bJlpd5bRKSEmV1sZssPvmeFX09LewqQJcm6PFOnTmXAgAFs\n3ryZ6667jnr16jF8+HA2bNjAW2+9xauvvsrjjz++d39LWg9g/PjxPPjgg2zcuJF27dpx3333pfpX\nEKlxZpZvZhvMrF7csVQHM7vQzN6ysOjGV2b2ppl1ibaVu+Z1NarucmT6lzelxlU5WZtV/VZTLrzw\nQi677DIAGjRoQJcuXTj77LMxM4499lhuvfVW3njjjb37J7fOr7nmGs4880zq1KnDDTfcwAcffFBz\nwYrEIJqU5EKgGLgqhe9bI31SZtYUeBH4HdCcMI3pMGBnyS6kafKrqXMi2aHKydq96rea0q5du/0e\nf/LJJ1xxxRUcffTRNGvWjPvvv5+vvvqq3OOPOmrfXAuNGzdm69atNRarSEwGAm8DI4GbSp40s4Zm\n9hsz+9zCspGzLFr6MaHlutHC0pADo+f/ZmbfS3iN/VqxUTn3NjNbDCyOnnvEzL4ws81mNtfMLkzY\nP8fMfmpmn5rZlmh7GzP7vZmVTEpSsu8LZnYHYUISd/eJ0aIcO919hrt/FM1M9kfgPDP72sw2RMde\nZmbvRzEsM7P7E163pAw9MNq21sx+mnSeRkaViY+As5PiGpIQ/0dmdnXS+fm7mf3WzNYD99tBlgiV\n2iury+DJZe3BgwfTqVMnli5dyubNmxk2bFip1rRILTOQsPDGM0DPkmkzCSthnQmcS1g28j+AYjNr\nB7xEaLm2BDoDByo5JX/A+hAS2qnR4zmE5SWbRzFMMrP60bZ7CMtR9nL3XMIUptsJ62P3K3lBMzuC\nsKTlM4QvAUVRAu1lZofvDcR9EfAD4G13b+ruLaJNW4Ebozm9Lwd+YGbJVYYLgBOBbwM/N7OToueH\nEhYsOY6w7OagpOM+BS6I4h8GjLWweliJc6J9jgQe5OBLhEotldXJOtnXX39Ns2bNaNSoEQUFBfv1\nV4vUNlEr9hhgYjQ16KfA9Ra+5d4M3OHuq6MW6jvuvhu4AXgtarkWuftGd59fibf9Hw/LSe4EcPdn\n3H2Tuxe7+8NAA8JCGQC3AP/l7p9G+y6I3m8usNnMLo326wfku/tX7v41+8r6TwBrzez5hC8hpbj7\nLHf/OLr/EWGq0YsTdyEsrbkr+l0/JCRTCEt6/iL6nVYCw5Nee7JHy2m6+yRgCdA1YZeV7v5Y9Pvv\n5ABLhErtlhXJOrkFXZ7f/OY3jBw5ktzcXH74wx/Sr1+//bYnvk5FX1Mkgw0Eprv7xujxeELLsCXQ\nkDB3d7J2wD+r8J77zTpkZveY2cKopL6RMA93y4T3KisGCEtvDojuD2DfQiB4WG/6e+5+DGEJzG8Q\n1r0uU7RIx8yoxL0JGJwQQ4k1Cfe3A02i+9+g9LKbia890MzmJfx+HZNeO3nk+IGWCJVaLCvWs166\ntPTn+YEHHij1XF5eHosWLSrzNerUqbP3Mi6A0aP3X4b30ksvLfN9RDKRmTUErgVyzGxV9HQDoBlw\nNGF1qeOBBUmHLmf/lmGibYT1nUuUtcDG3rJ41LL/D6C7uy+MntvAvqUpl0cxLCzjdcYCC8zsdOBk\nYGpZAbn7YjMbSSgv7/f+CZ4htIh7uvtuM3sYOKKs1ytDyZKeBdHjvUt6mtkxhNZ9d3d/O3puXsLv\nV1Y8B1oiVGqxrGhZi0ilfQfYA5xCKOmeQUh6bxJa3E8RlqI8Ohr0dG50adc44FIzu8bM6phZCzMr\nKQl/APyrhSUoTyCUsQ+kKWFt6/VmVt/Mfh49V+JJ4IHotTCzThaWzSQqOb9LaFFPLimrm9lJZna3\nmbWJHrcD+hMG0UFoIbe1/S9TawJsjBJ1V+D6pDgPVGabCPynmR1uZm2B2xO2HUYox38VncObCS39\nAyl3iVCp3ZSsRWqngcBT7r7S3deW3IA/EJLVvYRW9VxgPfBLIMfdlxMGQP2YsGTkPMIAMYCHCcl3\nNfA0ofWbKLkV+SrwCmFQ2GeE8nJiCfi3hOQ13cw2E5J3o4TtowjJL7EM9jVh0NZsM/sa+AcwP4oX\nYCbwMbDazNZGz/074UvBZuBnwLMHiTvx8TDgiyj+VxJjcfcCwkC9dwjnpCPwdw7sYEuESi2VFdON\nxs3SbLpRM+tF6KPLAUa4+0NJ2wcBv2JfX9vv3f2phG3/RfiD9KC7798fIJImzKwbMMbdj407FpGa\npmRdDdIpWVuYlnAxcCnwJaFl1C+6bKVkn0FAF3e/I+nY5oRv82cRSn/vAWe5++YUhS9SIVEZezww\nz90fjDsekZqmMnj26Qoscfdl0aU2EwjXtiYr68tFT8Lo4M3RZSPTgV41F6pI5UWTm2wEWhOu9xbJ\nekrW2acN+/f7rYieS/avZvaBmU0sGYxTxrEryzlWJDbuvsjdm7h7N3fXtIJSKyhZZ5+yWszJfRkv\nAMe6e2fgdfYNiqnIsSIikmJZcZ217GcFYVaqEm0Jfdd7JUyCAWH06S8Tjs1LOvZvyW9gZkrgIiKH\n4FDHN6llnX3mAidECxDUJ0zF+ELiDmaWOFlFH/ZN6PAq0MPMmkWDzXpEz5VSsoZ4Ot/uv//+2GNQ\nnIozk+PMhBgzKc6qyNhk3bRpU3Jzc8nNzaVOnTo0btx473Pjx48/5Nc977zzeOaZZ6ox0tRy9yLC\nxAzTCdeTTnD3AjMbZmZXRLvdEa0ANC/a96bo2I3AA4QR4bOBYR4GmomISIwytgz+9ddf773foUMH\nRowYQffu3WOMKH24+yvsWwyh5Ln7E+7/FPhp8nHRtpGE5RJFRCRNZGzLOlFZJYbi4mIeeOABjj/+\neFq1asWNN97Ili1bANi+fTv9+/fniCOOoHnz5px33nls3ryZH//4x8ydO5fvf//75Obm8pOf/CSO\nX0eqSV5eXtwhVIjirF6Ks/pkQoyQOXFWRVZMinLccccxYsQILrnkkr3P/fKXv+Tll19m4sSJNG/e\nnB/84AeYGSNGjGD48OH8/e9/Z+zYsdStW5d58+Zx6qmn0qhRI8477zzuuOMO+vfvX+H3T6dJUVIh\nU/5fiIikk6rkiiqXwW1Y1XOU31/9f/ifeOIJxo0bR+vWYZ33++67j9NOO40RI0ZQr1491q1bx5Il\nS+jYsSNdunTZPx4lIhERSSNVTtY1kWirw/Lly7nsssv2rktdkoA3bNjALbfcwurVq7nmmmvYtm0b\nN954I7/4xS+0hrWIiKSlrOizLkvbtm2ZOXMmGzZsYMOGDWzcuJFt27bRokUL6tevz7BhwygoKGDW\nrFlMmjSJCRMmAChhi4hI2snaZD148GCGDBnCihVhYam1a9cybdo0AF5//XUKCgpwd5o0aULdunWp\nWzcUGVq3bs3SpUtji1tERCRZViTrslrDQ4YMoUePHlxyySU0a9aMCy+8kHnz5gGwcuVK+vTpQ25u\nLqeffjpXXHEFffv2BeCuu+5i1KhRHHHEEdx7770p/T1ERETKkhWjweOm0eAiInIwVckVWdGyFhER\nyWYZO4OZiEiyouIiir047jCyRo7lUCenTtxhCErWIpKB3J0VW1Ywf818FqxdsPfn4vWLlayrUY7l\ncGKLEzm99el0atUp/GzdiXa57XTlTIqpz7oaqM9apOZs2bmFj9Z+xII1+5LygrULaFi34b4EEv08\n5chTaFi3YdwhZ43CPYUUrCvY7wvR/DXz2bF7B51ad+L0ViF5n976dE5rdRq5DXLjDjmtVSVXKFlX\nAyVrkarbU7yHJeuXlEoMa7et5dQjT92bkEuS85GHHRl3yLXWum3rwpemhC9QH6/7mFaHtSr1BerE\nI06kbo6KuKBkHTsla5HKWbN1DfPXzN8vKS/6ahHfaPqNUi2245sfr37TDFBUXMTSjUtLdU2s3LKS\nk1ueXOrftfVhrWtdKb3GknWjRo1WFxYWtj7kyGqJhg0brtmxY8dRcceRKkrWUlHbd29n4bqF+7XA\n5q+ZT5EXlWqBdWzVkSb1m8QdslSzbbu28fG6j8O//5oFzF8bvqTlWM7+feGtOtGxVUca12scd8g1\npsaStUhZlKwlWbEX89nGz0qVsL/Y/AXfPOKbpf4of6PpN2pdq0r2cXdWbV1V6kvc4vWLaZvbttSA\ntg7NO5BjmX+lsZK1pJSSde22YceGUn9kP173Mc0bNi/1R/akI06iXp16cYcsGWJ30W4Wr19c6kvf\n+u3r6diq435l9E6tOnFE4yPiDrlSlKwlpZSsa4ddRbtY9NWi/cqXC9YsYMvOLXRq3Wm/lvJprU6j\neaPmcYcsWWpT4aYyrwhoUr9JqarNyS1PpkHdBnGHXCYla0kpJevsUt41y59u+JRjDz82jMBOaNG0\nb9ZeJWyJnbvzxeYvSv2/XbpxKcc3P77UgLZ0uDZcyVpSSsk6c5V3zXKDOg1KlbBPaXkKjeo1ijtk\nkUop3FNYqiKUeG14Yiu8U+tOKb02XMlaUkrJOv1V9Jrlkj9YrQ5rFXfIIjXqq+1flRprsXDdQo48\n7MiUXRuuZC0ppWSdXnTNssihKbk2PPlLbU1dG65kLSmlZB2PkmuWkwd86ZplkepVcm14SUu85LNm\nZlW6NlzJWlJKybpmlVyznDxwRtcsi8SnOq4NV7KWlFKyrj47du9gzso5+334P1r7ES0atdA1yyIZ\noDLXhnc/rruStaSOknX12Fy4me6julMnpw5dju6ia5ZFskhZ14a/dctbStaSOkrWVbd993Z6ju1J\n59adGd57uMrYIrWAyuCSUkrWVbOraBd9JvThyMZHMvLqkVkx57GIHFxVkrX+SmQhM+tlZovMbLGZ\nDTnAfteYWbGZnRU9bm9m283s/ej2WOqirh2KiosY8NwAGtZtyFN9nlKiFpEK0YrgWcbMcoDfA5cC\nXwJzzex5d1+UtF8T4EfAO0kv8am7n5WSYGsZd2fwtMFs2LGBaddPq5FJF0QkO+lrffbpCixx92Xu\nvhuYAPQpY78HgIeAnUnPq/O0Brg7P57+Yz5a+xFT+02lYd2GcYckIhlEyTr7tAGWJzxeET23l5l1\nBtq6+0tlHH+smb1nZn8zswtrMM5a5cE3H+S1pa/x0g0vabISEak01eGyT1kt472jwSwMO34YGFTG\nMauAY9x9Y9SPPdXMTnX3rTUWbS3w6OxHGfXhKN68+U1aNGoRdzgikoGUrLPPCuCYhMdtCX3XJZoC\nHYH8KHEfBTxvZle5+/vALgB3f9/M/gl8E3g/+U2GDh26935eXh55eXnV+1tkidEfjuZX//gVs26e\nxVFNjoo7HBFJofz8fPLz86vltXTpVpYxszrAJ4QBZquAOUB/dy8oZ/+/AXe7+zwzawlscPdiM+sA\nvAF0cvdNScfo0q0KmFIwhdteuo2ZA2dyypGnxB2OiMSsKpduqWWdZdy9yMxuB6YTxiSMcPcCMxsG\nzHX3acmHsK8MfhHw32a2GygCBicnaqmYGUtnMHjaYF4Z8IoStYhUmVrWUmlqWR/Y28vf5qoJV/Hc\ntc/RrX23uMMRkTShSVFE0sT8NfO5+tmrGX31aCVqEak2StYi1WTJ+iX0HtebR3s/Su8Te8cdjohk\nESVrkWqwfPNyeozpwbC8YVzb8dq4wxGRLKNkLVJF67ato8eYHvyo64/4/lnfjzscEclCStYiVbC5\ncDM9x/ak76l9uef8e+IOR0SylEaDS6VpNHigNalFpDK0nrWklJK11qQWkcpTspaUqu3Juqi4iP6T\n+7O7eDeT+k7SUpciUiGawUwkRbQmtYjEQX9pRCoocU3qGQNnaE1qEUkZJWuRCipZkzr/pnytSS0i\nKaVkLVIBWpNaROKkZC1yEFqTWkTipmQtcgBTCqYwZMYQZg6cybGHHxt3OCJSSylZi5RDa1KLSFVt\n2QLz58MHH1TtdZSsRcrw9vK36T+5P89d+xxnHX1W3OGISJpzh5UrQ1JOvK1aBaedBmecUbXX16Qo\nUmnZPinK/DXz6TGmByP7jNRSlyJSyu7dsGjRvoT84YfhZ04OnHkmdO6873biiVA3ahZrBjNJqWxO\n1kvWLyFvVB4P93xYS12KCJs37ytjl9wKCuCYY/Yl5DPOCD+POgoOtESAkrWkVLYm6+Wbl9Pt6W78\n7KKfaalLkVrGHZYvL91aXr0aOnXav7XcqRMcdljl30PJWlIqG5P1um3r6PZ0N24961YtdSmS5Xbv\nDq3j5P7lBg32T8pnnBHK2HXqVM/7KllLSmVbst5cuJnuo7pz+YmX88AlD8QdjohUo02bSpexFy2C\n9u1LJ+ajangaBSVrSalsStZak1okO7jDF1+Ubi2vWwenn75/Yj7tNGjcOPUxKllLSmVLstaa1CKZ\nadcuWLhwX79yya1Ro/2TcufOcPzx1VfGriola0mpbEjWWpNaJDNs3Fg6KX/yCXToULqM3apV3NEe\nmJK1pFSmJ2t359YXb+XzTZ8z7fppWupSJA24w7JlpcvY69eHRFxyeVRJGbtRo7gjrjwla0mpTE7W\nJWtSv7X8LWYMnKGlLkVisHNnKGMnJuUPP4QmTUqXsTt0CJONZIOqJGvV/qRW0ZrUIqm1YUPpMvaS\nJaEvuaR8feWV4eeRR8YdbfpSy1oqLVNb1o/OfpThc4bz5s1vaqlLkWrmDp99Vrq1vHHj/iXszp2h\nY0doWAt7n1QGl5TKxGQ9+sPR/Gzmz5h18ywtdSlSRYWFZZexmzXbf/rNzp3huOOyp4xdVUrWsh8z\n6wU8AuQAI9z9oXL2uwaYCHzL3d+PnvtP4HvAHuBOd59exnEZlaynFEzhtpduY+bAmVrqUqSS1q8v\nnZQ//RROOKH0aOwjjog72vSmZC17mVkOsBi4FPgSmAv0c/dFSfs1Af4K1ANud/f3zewU4BngbKAt\nMAM4MTkzZ1KynrF0BtdPvp5XBryipS5FKsAd3n0XRo+G558PC1kkJ+VTT62dZeyq0gAzSdQVWOLu\nywDMbALQB1iUtN8DwEPATxKe6wNMcPc9wOdmtiR6vdk1HnUN0JrUIhW3bBmMHQtjxsCePTBwILz2\nGnzzmwdeSUpSQz0J2acNsDzh8Yroub3MrDPQ1t1fOsixK5OPzRTz18zn6mevZvTVo+nWvlvc4Yik\npS1b4KmnIC8PunSBFSvg6afDaO2f/xxOOkmJOl2oZZ19yvpo7a1ZW5j8+mFgUGWPTTR06NC99/Py\n8sjLy6tMjDVqyfol9B7Xm0d7P0rvE3vHHY5IWtmzB6ZPDy3ol1+G7t3hjjvg8svDqlNSffLz88nP\nz6+W11KfdZYxs3OBoe7eK3p8L+Alg8zMLBf4FNhKSM5HAeuBq4B/Iez8y2jfV4D73X120nukbZ+1\n1qQWKc0d5s0LCXr8+DBC+8Yb4brrNCgsldRnLYnmAieYWXtgFdAP6F+y0d23AHtn0DWzvwF3u/s8\nMysExpnZbwnl7xOAOakMvirWbVtHjzE9+FHXHylRixDK2uPGhSS9bVtI0LNmhX5oySxK1lnG3YvM\n7HZgOvsu3Sows2HAXHeflnwIUfnb3Rea2URgIbAbuC1tm9BJNhdupufYnvQ9tS/3nH9P3OGIxObr\nr+G550KCfv99uOYa+OMf4YILdL1zJlMZXCot3crgWpNaaruiInj99XC51bRp0K1bGM195ZW6xCqd\n6DprSal0StZak1pqs/nzQ4J+5hlo0yaUufv1S/+lImsr9VlLrVRUXMSA5wbQsG5DnurzlBK11Aqr\nVoXkPHp0mHd7wIDQqj5Fk/NlNSVryUjuzuBpg9mwYwPTrp9G3Rz9V5bstW0bTJ0a+qFnz4bvfAce\neQQuvlj90LWF/sJJxilZk/qjtR8xY+AMGtZVp5xkn6IiyM8PCXrqVDj/fBg0KAwea9w47ugk1ZSs\nJeNoTWrJZh9/HBL0uHHQsmUYKPbLX8JRWtW1VlOylozy6OxHGfXhKN68+U1aNGoRdzgi1WLNmjBZ\nyZgxsHp16Id++WU47bS4I5N0oWQtGWP0h6P51T9+xaybZ3FUEzUzJLPt2AEvvBAGir31Flx1FTz0\nUJj+s06duKOTdKNkLRlhSsEUhswYwsyBMzn28GPjDkfkkBQXw5tvhgQ9ZQp861vhcqtnn4Um6tGR\nA1CylrQ3Y+kMBk8bzCsDXuGUI3V9imSeTz4JJe6xY6Fp09APvWBBuDZapCKUrCWtaU1qyVRffQUT\nJoRW9PLlcP31YVT3GWdo2UmpPM1gJpWWqhnM5q+ZT48xPRjZZ6SWupSMUFgYpvscMyZcdnX55aEV\n/e1vQ101jWo9zWAmWUdrUkumcA8DxMaMgb/8JbScBw4Mj3Nz445OsoWStaSd5ZuX02NMD4blDePa\njtfGHY5ImT79dF8/dIMGYaDYvHlwzDFxRybZSMla0orWpJZ0tmEDTJwY+qH/+c+waMazz0KXLuqH\nlpqlPmuptJrqs95cuJnuo7pz+YmX88AlD1T764scil274KWXQoJ+/XXo1Su0onv2hHr14o5OMomW\nyJSUqolkrTWpJZ24hwUzxowJLeeOHUOCvuYaOPzwuKOTTKUBZpLRdhXt4rsTv8txhx/H73r/Tola\nYvPZZ6EPesyY8HjgQJg7F447Lt64RNSylkqrzpZ1UXER/Sf3Z3fxbib1naSlLiXlNm2CSZNCgi4o\ngGuvDUm6a1f1Q0v1UstaMpLWpJa47N4Nr7wSEvSrr4broO+5B3r3hvr1445OpDT9dZRYaE1qSTV3\neO+9MFBswgQ48cTQD/2nP0ELLeAmaU7JWmKhNaklVb74Yl8/9K5dIUH/4x9wwglxRyZScUrWknJa\nk1pq2pYtMHlyaEXPnw99+8KTT8L556sfWjKTkrWklNaklpqUnw9PPAF//Svk5cHtt4f5uRuql0Uy\nnEaDS6Ud6mjwKQVTuO2l25g5cKaWupRqVVQEP/95KHX/x3+EmcVatow7KpH9aTS4pD2tSS01ZdMm\nGDAAvv4a3n0XWrWKOyKR6pcTdwCS/UrWpJ587WStSS3VqqAAzjknTFoyY4YStWQvJWupUfPXzOfq\nZ69m9NWj6da+W9zhSBZ54QW4+GK491549FHN0y3ZTWVwqTFak1pqQnEx/OIX8Oc/w4svhpa1SLZT\nyzoLmVkvM1tkZovNbEgZ2web2Xwzm2dms8zs5Oj59ma23czej26PHWoMWpNaasKWLfDd74ZZx+bO\nVaKW2kOjwbOMmeUAi4FLgS+BuUA/d1+UsE8Td98a3b8SuM3de5tZe+BFdz/9IO9xwNHg67ato9vT\n3bj1rFu55/x7qv5LiQCLF8PVV0O3bqHsrWlBJdNUZTS4WtbZpyuwxN2XuftuYALQJ3GHkkQdaQIU\nJzyu0pSs+9moAAASkUlEQVQRmws303NsT/qe2leJWqrNSy/BhRfCnXfC448rUUvtoz7r7NMGWJ7w\neAUhge/HzG4D7gbqAZckbDrWzN4DtgD3ufvfK/rG23dv54rxV3BBuwv47+7/fUjBiyRyh4ceguHD\n4bnnQsIWqY2UrLNPWS3jUjVrd38MeMzM+gH3ATcBq4Bj3H2jmZ0FTDWzU5Na4gAMHTp07/28vDzO\n73a+1qSWarVtG9x8M3z+OcyZA23bxh2RSOXk5+eTn59fLa+lPussY2bnAkPdvVf0+F7A3f2hcvY3\nYKO7H17Gtr8B97j7+0nP79dnrTWppbotXRr6p7t0gT/+UdOFSnZQn7UkmgucEI3srg/0A15I3MHM\nEtcbuoIwIA0zaxkNUMPMOgAnAEsP9GaJa1KP/+54JWqpshkzwoIb//Zv8NRTStQioDJ41nH3IjO7\nHZhO+DI2wt0LzGwYMNfdpwG3m9m3gV3ARmBQdPhFwH+b2W6gCBjs7psO8F5ak1qqjTv89rfw61+H\n9abz8uKOSCR9qAwulVZSBv/FrF8w8eOJ5N+Ur6UupUq2b4dbbw3Th06ZAu3bxx2RSPVTGVxSrmRN\n6uk3TleilipZtmzfKO+//12JWqQsStZySH71j1/x2o2vaU1qqZL8fDj3XLjhBhg7Fho3jjsikfSk\nMrhUmpn5wrULtdSlHDJ3+MMfwhzfY8ZAjx5xRyRS86pSBleylko72HSjIgdSWAi33RbWnp46FTp0\niDsikdRQn7WIZIQVK8Kyllu3wttvK1GLVJSStYikxFtvQdeu8J3vwLPPwmGHxR2RSObQddYiUuMe\nfxzuuw9GjYLeWtpcpNKUrEWkxuzaBT/6Ebz5ZmhZn3hi3BGJZCYlaxGpEatWwTXXQKtW8M47kJsb\nd0QimUt91iJS7ebMCf3TPXvC5MlK1CJVpZa1iFSrp5+GIUPgySfhqqvijkYkOyhZi0i12L0b7r4b\npk+HN96AUzRnjki1UbIWkSpbuxb69oUmTWD2bDi81OroIlIV6rMWkSp57z04+2zo1g1eeEGJWqQm\nqGUtIods3Dj4f/8P/vjHMPJbRGqGkrWIVNqePWEQ2dSpMHMmdOoUd0Qi2U3JWkQqZf166NcPzGDu\nXGih5cxFapz6rEWkwj78MPRPn3kmvPSSErVIqqhlLSIVMnEi/Pu/w/Dh0L9/3NGI1C5K1iJyQEVF\n8LOfwfjx4RrqM8+MOyKR2kfJWkTKtXEjXH89FBaG/ukjj4w7IpHaSX3WIlKmjz8O83ufdFJoUStR\ni8RHyVpESpk6FfLyQvn7kUegXr24IxKp3VQGF5G9ioth2LCwGMdLL4WR3yISPyVrEQFgyxa48UbY\nsCH0T7duHXdEIlJCZXAR4ZNP4JxzoE0beP11JWqRdKNkLVLL/fWvYRGOu++Gxx6D+vXjjkhEkqkM\nLlJLucP//E9I0FOnwvnnxx2RiJRHLessZGa9zGyRmS02syFlbB9sZvPNbJ6ZzTKzkxO2/aeZLTGz\nAjP7l9RGLqmydWtYf/rFF0P/tBK1SHozd487BqlGZpYDLAYuBb4E5gL93H1Rwj5N3H1rdP9K4DZ3\n721mpwLjgLOBtsAM4ERP+k9iZslPSQb55z/h6qvDNdSPPQYNGsQdkUjtYGa4ux3KsWpZZ5+uwBJ3\nX+buu4EJQJ/EHUoSdaQJUBzdvwqY4O573P1zYEn0epIlXn01tKJ/+EN48kklapFMoT7r7NMGWJ7w\neAVlJFwzuw24G6gHXJJw7NsJu62MnpMM5w6//jX89rcwaRJcdFHcEYlIZShZZ5+ySiylatbu/hjw\nmJn1A+4DbqrosQBDhw7dez8vL4+8vLzKRyopsX073HILLFkCc+ZAu3ZxRyRSO+Tn55Ofn18tr6U+\n6yxjZucCQ929V/T4XsDd/aFy9jdgo7sfnryvmb0C3O/us5OOUZ91hvj8c/jOd+C00+CJJ6BRo7gj\nEqm91GctieYCJ5hZezOrD/QDXkjcwcxOSHh4BWFAGtF+/cysvpkdB5wAzElBzFIDZs6Ec8+FQYNg\n9GglapFMpjJ4lnH3IjO7HZhO+DI2wt0LzGwYMNfdpwG3m9m3gV3ARmBQdOxCM5sILAR2E0aJqwmd\nYdxh+HD43/+FcePg0kvjjkhEqkplcKk0lcHT144d8IMfwIcfwpQpcNxxcUckIiVUBhcRli8Po7x3\n7oS33lKiFskmStYiWeDNN8NCHH37wvjxcNhhcUckItVJfdYiGcwd/vQnGDoURo2CXr3ijkhEaoKS\ntUiG2rkTbr8d3n47lL1POOHgx4hIZlIZXCQDffkl5OXBhg0hWStRi2Q3JWuRDPPOO2ERjssvD1OH\nNm0ad0QiUtNUBhfJIE8+CT/9KYwYAVdeGXc0IpIqStYiGWDXLrjrLnj9dZg1C04++eDHiEj2ULIW\nSXNr1oRLspo1g9mzw08RqV3UZy2Sxt59F84+Owwme/55JWqR2kota5E0NXo03HNPWC3rO9+JOxoR\niZOStUia2bMHfvITmDYN8vOhY8e4IxKRuClZi6SRr76C666D+vVhzhxo3jzuiEQkHajPWiRNfPBB\n6J8+++zQqlaiFpESalmLpIEJE+BHP4Lf/z60rEVEEilZi8SoqChMcjJxIsyYAWecEXdEIpKOlKxF\nYrBmDYwbB089Ba1bw9y50LJl3FGJSLpSn7VIiuzcCZMnw1VXhRnIFiyAP/wBXntNiVpEDkwta5Ea\n5A7vvw8jR4Z+6U6dYNAgeOYZaNIk7uhEJFMoWYvUgNWrQ5l75EjYtg1uuimUuo89NubARCQjmbvH\nHYNkGDNz/b8pbedOePHFkKDfeivMOnbTTXDhhZCjDieRWs/McHc7lGPVshapAvcwf/eoUaHMfcYZ\nIUE/+ywcdljc0YlItlCyFjkEq1bB2LGhFb1zZ+iHfu89aN8+7shEJBspWYtUUGEhvPBCSNBvvw3f\n/S48/jhccAHYIRW2REQqRsla5ADcw8CwkSNDafuss0IretIklblFJHWUrEXKsHLlvjL3nj2hH3re\nPDjmmLgjE5HaSMlaJFJYCM8/HxL07NmhzP3kk3D++Spzi0i8lKylVnMPiXnkyFDa7tIltKInT4bG\njeOOTkQkULLOQmbWC3iEMJ3sCHd/KGn7XcD3gd3AOuB77r482lYEfAgYsMzdr05l7KmyciWMGROS\ndHFxSNAffADt2sUdmYhIaZoUJcuYWQ6wGLgU+BKYC/Rz90UJ+1wMzHb3QjP7AZDn7v2ibVvcPfcg\n75GRk6Ls2AFTp4YEPXcu9O0bBoudd57K3CJS8zQpiiTqCixx92UAZjYB6APsTdbu/kbC/u8ANyQ8\nzqq05Q7vvLOvzH322aEVPXUqNGoUd3QiIhWjZJ192gDLEx6vICTw8twCvJzwuIGZzQH2AA+5+/PV\nH2LNW758X5k7Jyck6PnzoW3buCMTEak8JevsU1bLuMyatZkNALoAFyc8fYy7rzaz44CZZjbf3T+r\ngTir3fbt+8rc774L114Lo0fDOeeozC0imU3JOvusABKvBm5L6Lvej5l9G/hP4CJ3313yvLuvjn5+\nZmb5wJlAqWQ9dOjQvffz8vLIy8urluAryx3+8Y+QoCdPDon5e98Ll2CpzC0iccrPzyc/P79aXksD\nzLKMmdUBPiEMMFsFzAH6u3tBwj5nApOAnu7+z4TnDwe2u/suM2sJvAX0SRycFu0X+wCzL77YV+au\nWzeUuQcMgDZtYg1LRKRcGmAme7l7kZndDkxn36VbBWY2DJjr7tOA/wMOAyaZWeIlWqcAj0eXb+UA\n/5ucqOO0fTs891xI0PPmwXXXhVnGunZVmVtEspta1lJpqWxZu4e1oUvK3OedF1rRV10FDRumJAQR\nkWqhlrVknWXLwuCwUaOgfn24+Wb4+GP4xjfijkxEJPWUrCVtbNu2r8z94YehzD1+PHzrWypzi0jt\npjK4VFp1lsHd4c03Q4KeMiWsDT1oEFx5pcrcIpJdqlIGV7KWSquOZP355/vK3A0bhjL3DTfA0UdX\nT4wiIulGfdaSEbZuDYPERo6EBQugXz949tmw0pXK3CIi5VPLWiqtMi3r4uL9y9zduoXR3FdcAQ0a\n1GiYIiJpRWVwSamKJOulS/eVuZs0CQn6hhvgqKNSE6OISLpRGVzSwtat8Je/hFb0xx9D//6h7H3m\nmSpzi4hUhVrWUmmJLeviYnjjjZCgn38eLrootKIvv1xlbhGRRCqDS0qZmX/6qe8tc+fmhtHc118P\nrVvHHZ2ISHpSspaUMjNv2dK5/vrQiu7cWWVuEZGDUbKWlDIz37nTqV8/7khERDJHVZJ1TnUHI7WD\nErWISOooWYuIiKQ5JWsREZE0p2QtIiKS5pSsRURE0pyStYiISJpTshYREUlzStYiIiJpTslaREQk\nzSlZi4iIpDklaxERkTSnZC0iIpLmlKxFRETSnJK1iIhImlOyFhERSXNK1iIiImlOyToLmVkvM1tk\nZovNbEgZ2+8ys4/N7AMze83M2iVsGxQd94mZDUxt5CIiUhYl6yxjZjnA74GeQEegv5mdnLTb+0AX\nd+8MTAZ+FR3bHPg5cDZwDnC/mTVLVezVLT8/P+4QKkRxVi/FWX0yIUbInDirQsk6+3QFlrj7Mnff\nDUwA+iTu4O5vuHth9PAdoE10vycw3d03u/smYDrQK0VxV7tM+QArzuqlOKtPJsQImRNnVShZZ582\nwPKExyvYl4zLcgvwcjnHrjzIsSIikgJ14w5Aqp2V8ZyXuaPZAKALcHFljxURkdQxd/0tziZmdi4w\n1N17RY/vBdzdH0ra79vA74CL3H199Fw/IM/dfxA9/hPwN3d/NulY/acRETkE7l5Wo+iglKyzjJnV\nAT4BLgVWAXOA/u5ekLDPmcAkoKe7/zPh+ebAu8BZhC6SdwkD0Tal7jcQEZFkKoNnGXcvMrPbCYPD\ncoAR7l5gZsOAue4+Dfg/4DBgkpkZsMzdr3b3jWb2ACFJOzBMiVpEJH5qWYuIiKQ5jQaXclVgcpX6\nZjbBzJaY2dtmdkyaxjnIzNaa2fvR7XsxxDjCzNaY2fwD7DM8OpcfmFnnVMaXEMMB4zSzi81sU8K5\n/FkMMbY1s5lmttDMFpjZHeXsF+v5rEicaXI+G5jZbDObF8V5fxn7xP5Zr2CcsX/WE2LJiWJ4oYxt\nlT+f7q6bbqVuhC9ynwLtgXrAB8DJSfv8EHgsun8dMCFN4xwEDI/5fF4IdAbml7O9N/DX6P45wDtp\nGufFwAsxn8ujgM7R/SaEMRrJ/+axn88Kxhn7+YziaBz9rEOYe6Fr0vbYP+sVjDP2z3pCLHcBY8v6\n9z2U86mWtZTnoJOrRI9HRff/QhjUlmoViRPKviwtZdz978DGA+zSBxgd7TsbaGZmrVMRW6IKxAnx\nn8vV7v5BdH8rUEDp+QBiP58VjBNiPp8A7r49utuAMJYpuX80HT7rFYkT0uB8mllb4DLgyXJ2qfT5\nVLKW8lRkcpW9+7h7EbDJzFqkJrzSMUTKmwTmX6Ny6MTog5RuMmlCmnOjUuRfzezUOAMxs2MJlYDZ\nSZvS6nweIE5Ig/MZlWznAauB19x9btIu6fBZr0ickB6f9YeBn1D+PBWVPp9K1lKeikyQkryPlbFP\nTatInC8Ax3qYC/119n2jTSeZMiHNe0B7dz+TMAf91LgCMbMmhFbJnVHLdb/NZRwSy/k8SJxpcT7d\nvTiKoS1wThlfGtLhs16ROGP/rJvZ5cCaqKpilP1/sdLnU8layrMCSBz00Bb4Mmmf5UA72Ht9d667\nH6yEWt0OGqe7b4xK5AB/Jszalm5WEJ3LSFnnO3buvrWkFOnuLwP1Ymph1SUkwDHu/nwZu6TF+TxY\nnOlyPhPi2QLkU3pNgHT4rO9VXpxp8lm/ALjKzJYC44HuZjY6aZ9Kn08laynPXOAEM2tvZvWBfoRv\nrYleJAzoAOgLzExhfCUOGqeZHZXwsA+wMIXx7RcK5fenvQAMhL2z0G1y9zWpCixJuXEm9vuaWVfC\n5Z8bUhVYgqeAhe7+u3K2p8v5PGCc6XA+zaylRavrmVkj4NvAoqTdYv+sVyTOdPisu/tP3f0Yd+9A\n+Hs0092Tlxuu9PnUpChSJq/Y5CojgDFmtgRYT/iPmY5x3mFmVwG7gQ3ATamO08yeAfKAI8zsC+B+\noH74FfwJd3/JzC4zs0+BbcDNqY6xInEC15jZDwnncgdhJGuqY7wAuAFYEPVfOvBTwhUBaXM+KxIn\naXA+gaOBURaW180Bno3OX1p91isYZ+yf9fJU9XxqUhQREZE0pzK4iIhImlOyFhERSXNK1iIiImlO\nyVpERCTNKVmLiIikOSVrERGRNKdkLSIikuaUrEVERNLc/wc3gbRxsXTzqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72c7670b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEZCAYAAACjPJNSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72c722ea50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as p\n",
    "%matplotlib inline\n",
    "model.summary()\n",
    "print (history.params)\n",
    "\n",
    "x = history.epoch\n",
    "y_acc = history.history[\"acc\"]\n",
    "y_accVal = history.history['val_acc']\n",
    "\n",
    "print(type(x))\n",
    "print(type(y_acc))\n",
    "p.plot(x, y_acc, label='Train')\n",
    "p.plot(x, y_accVal, label='Test')\n",
    "p.legend(bbox_to_anchor=(0, 1),\n",
    "           bbox_transform=p.gcf().transFigure)\n",
    "title = 'Model base' + '\\nAccuracy' + 'Standard'\n",
    "p.title(title)\n",
    "\n",
    "p.show()\n",
    "\n",
    "y_loss = history.history[\"loss\"]\n",
    "y_lossVal = history.history['val_loss']\n",
    "p.plot(x, y_loss, label='Train')\n",
    "p.plot(x, y_lossVal, label='Test')\n",
    "p.legend(bbox_to_anchor=(1, 1),\n",
    "           bbox_transform=p.gcf().transFigure)\n",
    "title1 = 'Model base' + '\\nLoss' + 'Standard'\n",
    "p.title(title1)\n",
    "\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/40\n",
      "950/950 [==============================] - 5s - loss: 2.5647 - acc: 0.1716 - val_loss: 2.0381 - val_acc: 0.3600\n",
      "Epoch 2/40\n",
      "950/950 [==============================] - 5s - loss: 1.9362 - acc: 0.2232 - val_loss: 1.7080 - val_acc: 0.5000\n",
      "Epoch 3/40\n",
      "950/950 [==============================] - 5s - loss: 1.7239 - acc: 0.3147 - val_loss: 1.6268 - val_acc: 0.4200\n",
      "Epoch 4/40\n",
      "950/950 [==============================] - 5s - loss: 1.6080 - acc: 0.4042 - val_loss: 1.4475 - val_acc: 0.5200\n",
      "Epoch 5/40\n",
      "950/950 [==============================] - 5s - loss: 1.4499 - acc: 0.4853 - val_loss: 1.4716 - val_acc: 0.4600\n",
      "Epoch 6/40\n",
      "950/950 [==============================] - 5s - loss: 1.4183 - acc: 0.5053 - val_loss: 1.3427 - val_acc: 0.5000\n",
      "Epoch 7/40\n",
      "950/950 [==============================] - 5s - loss: 1.3357 - acc: 0.5389 - val_loss: 1.3182 - val_acc: 0.5000\n",
      "Epoch 8/40\n",
      "950/950 [==============================] - 5s - loss: 1.2522 - acc: 0.5495 - val_loss: 1.2987 - val_acc: 0.5200\n",
      "Epoch 9/40\n",
      "950/950 [==============================] - 5s - loss: 1.2704 - acc: 0.5442 - val_loss: 1.2778 - val_acc: 0.5400\n",
      "Epoch 10/40\n",
      "950/950 [==============================] - 5s - loss: 1.2170 - acc: 0.5684 - val_loss: 1.2586 - val_acc: 0.5000\n",
      "Epoch 11/40\n",
      "950/950 [==============================] - 5s - loss: 1.2201 - acc: 0.5579 - val_loss: 1.2179 - val_acc: 0.4400\n",
      "Epoch 12/40\n",
      "950/950 [==============================] - 5s - loss: 1.1687 - acc: 0.5684 - val_loss: 1.2202 - val_acc: 0.5000\n",
      "Epoch 13/40\n",
      "950/950 [==============================] - 5s - loss: 1.1338 - acc: 0.5884 - val_loss: 1.2794 - val_acc: 0.5200\n",
      "Epoch 14/40\n",
      "950/950 [==============================] - 5s - loss: 1.1672 - acc: 0.5326 - val_loss: 1.2650 - val_acc: 0.5000\n",
      "Epoch 15/40\n",
      "950/950 [==============================] - 5s - loss: 1.1126 - acc: 0.5905 - val_loss: 1.3007 - val_acc: 0.5200\n",
      "Epoch 16/40\n",
      "950/950 [==============================] - 5s - loss: 1.1010 - acc: 0.5726 - val_loss: 1.0936 - val_acc: 0.4800\n",
      "Epoch 17/40\n",
      "950/950 [==============================] - 5s - loss: 1.1169 - acc: 0.5789 - val_loss: 1.3226 - val_acc: 0.5000\n",
      "Epoch 18/40\n",
      "950/950 [==============================] - 5s - loss: 1.0971 - acc: 0.5674 - val_loss: 1.2023 - val_acc: 0.4200\n",
      "Epoch 19/40\n",
      "950/950 [==============================] - 5s - loss: 1.0677 - acc: 0.5874 - val_loss: 1.1242 - val_acc: 0.5400\n",
      "Epoch 20/40\n",
      "950/950 [==============================] - 5s - loss: 1.0679 - acc: 0.5779 - val_loss: 1.3538 - val_acc: 0.4600\n",
      "Epoch 21/40\n",
      "950/950 [==============================] - 5s - loss: 1.0605 - acc: 0.5968 - val_loss: 1.3546 - val_acc: 0.4600\n",
      "Epoch 22/40\n",
      "950/950 [==============================] - 5s - loss: 1.0883 - acc: 0.5768 - val_loss: 1.1856 - val_acc: 0.5000\n",
      "Epoch 23/40\n",
      "950/950 [==============================] - 5s - loss: 1.0597 - acc: 0.5853 - val_loss: 1.2155 - val_acc: 0.5200\n",
      "Epoch 24/40\n",
      "950/950 [==============================] - 5s - loss: 1.0289 - acc: 0.5958 - val_loss: 1.2334 - val_acc: 0.5400\n",
      "Epoch 25/40\n",
      "950/950 [==============================] - 5s - loss: 1.0994 - acc: 0.5632 - val_loss: 1.2433 - val_acc: 0.5000\n",
      "Epoch 26/40\n",
      "950/950 [==============================] - 5s - loss: 1.0653 - acc: 0.5726 - val_loss: 1.2301 - val_acc: 0.4800\n",
      "Epoch 27/40\n",
      "950/950 [==============================] - 5s - loss: 1.0386 - acc: 0.5895 - val_loss: 1.2039 - val_acc: 0.5000\n",
      "Epoch 28/40\n",
      "950/950 [==============================] - 5s - loss: 1.0081 - acc: 0.5968 - val_loss: 1.2104 - val_acc: 0.5000\n",
      "Epoch 29/40\n",
      "950/950 [==============================] - 5s - loss: 1.0089 - acc: 0.5979 - val_loss: 1.1391 - val_acc: 0.4800\n",
      "Epoch 30/40\n",
      "950/950 [==============================] - 5s - loss: 0.9956 - acc: 0.6126 - val_loss: 1.1649 - val_acc: 0.5800\n",
      "Epoch 31/40\n",
      "950/950 [==============================] - 5s - loss: 0.9882 - acc: 0.6189 - val_loss: 1.0994 - val_acc: 0.5200\n",
      "Epoch 32/40\n",
      "950/950 [==============================] - 5s - loss: 1.0008 - acc: 0.6063 - val_loss: 1.1357 - val_acc: 0.5400\n",
      "Epoch 33/40\n",
      "950/950 [==============================] - 5s - loss: 0.9854 - acc: 0.6084 - val_loss: 1.2350 - val_acc: 0.5200\n",
      "Epoch 34/40\n",
      "950/950 [==============================] - 5s - loss: 0.9856 - acc: 0.6095 - val_loss: 1.1956 - val_acc: 0.4800\n",
      "Epoch 35/40\n",
      "950/950 [==============================] - 5s - loss: 0.9431 - acc: 0.6179 - val_loss: 1.1116 - val_acc: 0.5200\n",
      "Epoch 36/40\n",
      "950/950 [==============================] - 5s - loss: 0.9325 - acc: 0.6400 - val_loss: 1.1342 - val_acc: 0.5200\n",
      "Epoch 37/40\n",
      "950/950 [==============================] - 5s - loss: 0.9482 - acc: 0.6400 - val_loss: 1.2663 - val_acc: 0.4800\n",
      "Epoch 38/40\n",
      "950/950 [==============================] - 5s - loss: 0.9251 - acc: 0.6179 - val_loss: 1.1528 - val_acc: 0.5000\n",
      "Epoch 39/40\n",
      "950/950 [==============================] - 5s - loss: 0.9076 - acc: 0.6463 - val_loss: 1.3702 - val_acc: 0.4800\n",
      "Epoch 40/40\n",
      "950/950 [==============================] - 5s - loss: 0.9071 - acc: 0.6484 - val_loss: 1.1671 - val_acc: 0.5000\n",
      "1000/1000 [==============================] - 1s     \n",
      "Test loss / test accuracy = 1.2958 / 0.4980\n",
      "acc: 49.80%\n",
      " Not the best !\n"
     ]
    }
   ],
   "source": [
    "qrnn2 = Sequential()\n",
    "qrnn2.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE,\n",
    "                   input_length=query_maxlen))\n",
    "\n",
    "qrnn2.add(Dropout(0.3))\n",
    "qrnn2.add(RNN(EMBED_HIDDEN_SIZE, return_sequences=False))\n",
    "qrnn2.add(Dense(EMBED_HIDDEN_SIZE, activation='relu'))\n",
    "qrnn2.add(RepeatVector(story_maxlen))\n",
    "\n",
    "sentrnn2 = Sequential()\n",
    "sentrnn2.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE,\n",
    "                      input_length=story_maxlen))\n",
    "sentrnn2.add(Dropout(0.3))\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Merge([sentrnn, qrnn], mode='sum'))\n",
    "model2.add(RNN(EMBED_HIDDEN_SIZE, return_sequences=False))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Training')\n",
    "history2 = model2.fit([X, Xq], Y, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, validation_split=0.05)\n",
    "loss, acc = model2.evaluate([tX, tXq], tY, batch_size=BATCH_SIZE)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))\n",
    "print(\"%s: %.2f%%\" % (model2.metrics_names[1], acc*100))\n",
    "if (acc*100) < best:\n",
    "    print(\" Not the best !\")\n",
    "else:\n",
    "    print(\" We found a winner !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0bcb112fe73f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhistory2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_acc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_accVal2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "model2.summary()\n",
    "print (history2.params)\n",
    "\n",
    "y_acc2 = history2.history[\"acc\"]\n",
    "y_accVal2 = history2.history['val_acc']\n",
    "\n",
    "p.plot(x, y_acc2, label='Train')\n",
    "p.plot(x, y_accVal2, label='Test')\n",
    "p.legend(bbox_to_anchor=(1, 1),\n",
    "           bbox_transform=p.gcf().transFigure)\n",
    "title = 'Model LSTM + Dense relu' + '\\nAccuracy' + '\\nStandard'\n",
    "p.title(title)\n",
    "p.title(title1)\n",
    "p.show()\n",
    "\n",
    "y_loss2 = history2.history[\"loss\"]\n",
    "y_lossVal2 = history2.history['val_loss']\n",
    "p.plot(x, y_loss2, label='Train')\n",
    "p.plot(x, y_lossVal2, label='Test')\n",
    "p.legend(bbox_to_anchor=(1, 1),\n",
    "           bbox_transform=p.gcf().transFigure)\n",
    "title1 = 'Model LSTM + Dense relu' + '\\nLoss' + '\\nStandard'\n",
    "p.title(title)\n",
    "\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print([key for key in word_idx.keys() if word_idx[key] == 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/50\n",
      "950/950 [==============================] - 5s - loss: 2.6023 - acc: 0.1547 - val_loss: 1.8717 - val_acc: 0.2800\n",
      "Epoch 2/50\n",
      "950/950 [==============================] - 5s - loss: 1.8166 - acc: 0.2516 - val_loss: 1.6293 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "950/950 [==============================] - 6s - loss: 1.6664 - acc: 0.3537 - val_loss: 1.5960 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "950/950 [==============================] - 5s - loss: 1.5646 - acc: 0.4263 - val_loss: 1.4819 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "950/950 [==============================] - 5s - loss: 1.5077 - acc: 0.4695 - val_loss: 1.4312 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "950/950 [==============================] - 5s - loss: 1.4714 - acc: 0.4768 - val_loss: 1.3753 - val_acc: 0.5400\n",
      "Epoch 7/50\n",
      "950/950 [==============================] - 5s - loss: 1.4089 - acc: 0.5074 - val_loss: 1.4167 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "950/950 [==============================] - 5s - loss: 1.3740 - acc: 0.5084 - val_loss: 1.3616 - val_acc: 0.5400\n",
      "Epoch 9/50\n",
      "950/950 [==============================] - 5s - loss: 1.3438 - acc: 0.5274 - val_loss: 1.5100 - val_acc: 0.4600\n",
      "Epoch 10/50\n",
      "950/950 [==============================] - 5s - loss: 1.3138 - acc: 0.5200 - val_loss: 1.3827 - val_acc: 0.4800\n",
      "Epoch 11/50\n",
      "950/950 [==============================] - 5s - loss: 1.2957 - acc: 0.5053 - val_loss: 1.3657 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "950/950 [==============================] - 5s - loss: 1.2670 - acc: 0.5158 - val_loss: 1.4552 - val_acc: 0.4800\n",
      "Epoch 13/50\n",
      "950/950 [==============================] - 5s - loss: 1.3076 - acc: 0.5158 - val_loss: 1.4067 - val_acc: 0.5200\n",
      "Epoch 14/50\n",
      "950/950 [==============================] - 5s - loss: 1.2454 - acc: 0.5337 - val_loss: 1.3867 - val_acc: 0.4600\n",
      "Epoch 15/50\n",
      "950/950 [==============================] - 5s - loss: 1.2508 - acc: 0.5337 - val_loss: 1.3481 - val_acc: 0.5200\n",
      "Epoch 16/50\n",
      "950/950 [==============================] - 5s - loss: 1.2067 - acc: 0.5442 - val_loss: 1.2902 - val_acc: 0.5200\n",
      "Epoch 17/50\n",
      "950/950 [==============================] - 5s - loss: 1.2173 - acc: 0.5295 - val_loss: 1.3228 - val_acc: 0.5200\n",
      "Epoch 18/50\n",
      "950/950 [==============================] - 5s - loss: 1.2124 - acc: 0.5474 - val_loss: 1.3250 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "950/950 [==============================] - 5s - loss: 1.1813 - acc: 0.5253 - val_loss: 1.2908 - val_acc: 0.5600\n",
      "Epoch 20/50\n",
      "950/950 [==============================] - 5s - loss: 1.1662 - acc: 0.5579 - val_loss: 1.2807 - val_acc: 0.5400\n",
      "Epoch 21/50\n",
      "950/950 [==============================] - 5s - loss: 1.2138 - acc: 0.5463 - val_loss: 1.3407 - val_acc: 0.4800\n",
      "Epoch 22/50\n",
      "950/950 [==============================] - 5s - loss: 1.1213 - acc: 0.5853 - val_loss: 1.2756 - val_acc: 0.5200\n",
      "Epoch 23/50\n",
      "950/950 [==============================] - 5s - loss: 1.1416 - acc: 0.5726 - val_loss: 1.2955 - val_acc: 0.5400\n",
      "Epoch 24/50\n",
      "950/950 [==============================] - 5s - loss: 1.1426 - acc: 0.5526 - val_loss: 1.3385 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "950/950 [==============================] - 5s - loss: 1.1342 - acc: 0.5568 - val_loss: 1.2424 - val_acc: 0.5200\n",
      "Epoch 26/50\n",
      "950/950 [==============================] - 6s - loss: 1.1273 - acc: 0.5558 - val_loss: 1.3105 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "950/950 [==============================] - 6s - loss: 1.0896 - acc: 0.5779 - val_loss: 1.2269 - val_acc: 0.5200\n",
      "Epoch 28/50\n",
      "950/950 [==============================] - 6s - loss: 1.0961 - acc: 0.5600 - val_loss: 1.2040 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "950/950 [==============================] - 6s - loss: 1.0838 - acc: 0.5674 - val_loss: 1.3253 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "950/950 [==============================] - 6s - loss: 1.1002 - acc: 0.5621 - val_loss: 1.3594 - val_acc: 0.5800\n",
      "Epoch 31/50\n",
      "950/950 [==============================] - 6s - loss: 1.0671 - acc: 0.5695 - val_loss: 1.3646 - val_acc: 0.4600\n",
      "Epoch 32/50\n",
      "950/950 [==============================] - 5s - loss: 1.0820 - acc: 0.5695 - val_loss: 1.2630 - val_acc: 0.5200\n",
      "Epoch 33/50\n",
      "950/950 [==============================] - 6s - loss: 1.0426 - acc: 0.5789 - val_loss: 1.2028 - val_acc: 0.5400\n",
      "Epoch 34/50\n",
      "950/950 [==============================] - 6s - loss: 1.0540 - acc: 0.5863 - val_loss: 1.2999 - val_acc: 0.5200\n",
      "Epoch 35/50\n",
      "950/950 [==============================] - 5s - loss: 1.0599 - acc: 0.5779 - val_loss: 1.2735 - val_acc: 0.5600\n",
      "Epoch 36/50\n",
      "950/950 [==============================] - 5s - loss: 1.0362 - acc: 0.5937 - val_loss: 1.2660 - val_acc: 0.5400\n",
      "Epoch 37/50\n",
      "950/950 [==============================] - 6s - loss: 1.0583 - acc: 0.5653 - val_loss: 1.3276 - val_acc: 0.5000\n",
      "Epoch 38/50\n",
      "950/950 [==============================] - 6s - loss: 1.0758 - acc: 0.5589 - val_loss: 1.2972 - val_acc: 0.5400\n",
      "Epoch 39/50\n",
      "950/950 [==============================] - 5s - loss: 1.0483 - acc: 0.5621 - val_loss: 1.2951 - val_acc: 0.5400\n",
      "Epoch 40/50\n",
      "950/950 [==============================] - 5s - loss: 1.0544 - acc: 0.5589 - val_loss: 1.2893 - val_acc: 0.5600\n",
      "Epoch 41/50\n",
      "950/950 [==============================] - 6s - loss: 1.0011 - acc: 0.6147 - val_loss: 1.3289 - val_acc: 0.5000\n",
      "Epoch 42/50\n",
      "950/950 [==============================] - 6s - loss: 1.0165 - acc: 0.5747 - val_loss: 1.2532 - val_acc: 0.5600\n",
      "Epoch 43/50\n",
      "950/950 [==============================] - 6s - loss: 1.0164 - acc: 0.5789 - val_loss: 1.2797 - val_acc: 0.5600\n",
      "Epoch 44/50\n",
      "950/950 [==============================] - 6s - loss: 0.9853 - acc: 0.5800 - val_loss: 1.3678 - val_acc: 0.5400\n",
      "Epoch 45/50\n",
      "950/950 [==============================] - 6s - loss: 0.9924 - acc: 0.5968 - val_loss: 1.4011 - val_acc: 0.5200\n",
      "Epoch 46/50\n",
      "950/950 [==============================] - 6s - loss: 0.9905 - acc: 0.5905 - val_loss: 1.3073 - val_acc: 0.5200\n",
      "Epoch 47/50\n",
      "950/950 [==============================] - 5s - loss: 0.9915 - acc: 0.5979 - val_loss: 1.2721 - val_acc: 0.5200\n",
      "Epoch 48/50\n",
      "950/950 [==============================] - 5s - loss: 0.9958 - acc: 0.5895 - val_loss: 1.2915 - val_acc: 0.5200\n",
      "Epoch 49/50\n",
      "950/950 [==============================] - 6s - loss: 0.9847 - acc: 0.6137 - val_loss: 1.2510 - val_acc: 0.5400\n",
      "Epoch 50/50\n",
      "950/950 [==============================] - 5s - loss: 0.9836 - acc: 0.5884 - val_loss: 1.3064 - val_acc: 0.5400\n",
      "1000/1000 [==============================] - 1s     \n",
      "Test loss / test accuracy = 1.2556 / 0.5120\n",
      "acc: 51.20%\n"
     ]
    }
   ],
   "source": [
    "RNN = recurrent.LSTM\n",
    "EMBED_HIDDEN_SIZE = 50\n",
    "SENT_HIDDEN_SIZE = 100\n",
    "QUERY_HIDDEN_SIZE = 100\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "\n",
    "\n",
    "qrnn3 = Sequential()\n",
    "qrnn3.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE,\n",
    "                   input_length=query_maxlen))\n",
    "\n",
    "qrnn3.add(Dropout(0.3))\n",
    "qrnn3.add(RNN(EMBED_HIDDEN_SIZE, return_sequences=False))\n",
    "qrnn3.add(RepeatVector(story_maxlen))\n",
    "\n",
    "sentrnn3 = Sequential()\n",
    "sentrnn3.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE,\n",
    "                      input_length=story_maxlen))\n",
    "sentrnn3.add(Dropout(0.3))\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Merge([sentrnn, qrnn], mode='sum'))\n",
    "model3.add(RNN(EMBED_HIDDEN_SIZE, return_sequences=False))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Training')\n",
    "history3 = model3.fit([X, Xq], Y, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, validation_split=0.05)\n",
    "loss, acc = model3.evaluate([tX, tXq], tY, batch_size=BATCH_SIZE)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))\n",
    "print(\"%s: %.2f%%\" % (model3.metrics_names[1], acc*100))\n",
    "\n",
    "if (acc*100) < best:\n",
    "    print(\" Not the best !\")\n",
    "else:\n",
    "    print(\" We found a winner !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 66, 50)        1100                                         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 66, 50)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 66, 50)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 4, 50)         1100                                         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4, 50)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 50)            20200                                        \n",
      "____________________________________________________________________________________________________\n",
      "repeatvector_1 (RepeatVector)    (None, 66, 50)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                    (None, 100)           60400       merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 100)           0           lstm_6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 22)            2222        dropout_9[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 85,022\n",
      "Trainable params: 85,022\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "{'verbose': 1, 'nb_epoch': 40, 'batch_size': 32, 'metrics': ['loss', 'acc', 'val_loss', 'val_acc'], 'nb_sample': 950, 'do_validation': True}\n"
     ]
    }
   ],
   "source": [
    "model3.summary()\n",
    "print (history3.params)\n",
    "\n",
    "y_acc3 = history3.history[\"acc\"]\n",
    "y_accVal3 = history3.history['val_acc']\n",
    "\n",
    "p.plot(x,y_acc3, label='Train')\n",
    "p.plot(x,y_accVal3, label='Test')\n",
    "p.legend(bbox_to_anchor=(1, -1),\n",
    "           bbox_transform=p.gcf().transFigure)\n",
    "title = 'Model LSTM + Dense relu' + '\\nAccuracy' + '\\nEMBED_HIDDEN_SIZE = 100'\n",
    "p.title(title)\n",
    "\n",
    "p.show()\n",
    "\n",
    "y_loss3 = history3.history[\"loss\"]\n",
    "y_lossVal3 = history3.history['val_loss']\n",
    "p.plot(x, y_loss3, label='Train')\n",
    "p.plot(x, y_lossVal3, label='Test')\n",
    "p.legend(bbox_to_anchor=(1, -1),\n",
    "           bbox_transform=p.gcf().transFigure)\n",
    "title = 'Model LSTM + Dense relu' + '\\nLoss'  + '\\nEMBED_HIDDEN_SIZE = 100'\n",
    "p.title(title)\n",
    "\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4], [8, 5], [], [], [], [], [], [], [], []]\n",
      "[[4], [8, 5], [0], [0], [0], [0], [0], [0], [0], [0]]\n"
     ]
    }
   ],
   "source": [
    "liste = [[4], [8,5], []]\n",
    "for i in range(10-len(liste)):\n",
    "    pad = []\n",
    "    liste.append(pad)\n",
    "print(liste)\n",
    "x = [w if w else [0] for w in liste]\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_stories2(lines, only_supporting=False):\n",
    "    '''Parse stories provided in the bAbi tasks format\n",
    "    If only_supporting is true, only the sentences that support the answer are kept.\n",
    "    '''\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            substory = None\n",
    "            if only_supporting:\n",
    "                # Only select the relMAated substory\n",
    "                supporting = map(int, supporting.split())\n",
    "                substory = [story[i - 1] for i in supporting]\n",
    "            else:\n",
    "                # Provide all the substories\n",
    "                substory = [x for x in story if x]\n",
    "                for i in range(10-len(substory)):\n",
    "                    substory.append([])\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data\n",
    "\n",
    "\n",
    "def vectorize_stories2(data, word_idx, story_maxlen, query_maxlen):\n",
    "    X = []\n",
    "    Xq = []\n",
    "    Y = []\n",
    "    for story, query, answer in data:\n",
    "        x = [word_idx[w] for w in story if w else 0]\n",
    "        xq = [word_idx[w] for w in query]\n",
    "        y = np.zeros(len(word_idx) + 1)  # let's not forget that index 0 is reserved\n",
    "        y[word_idx[answer]] = 1\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "    return pad_sequences(X, maxlen=story_maxlen), pad_sequences(Xq, maxlen=query_maxlen), np.array(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the supporting ! RN which have to learn where is the answer\n",
    "RNN = recurrent.LSTM\n",
    "EMBED_HIDDEN_SIZE = 50\n",
    "SENT_HIDDEN_SIZE = 100\n",
    "QUERY_HIDDEN_SIZE = 100\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "\n",
    "qrnn4 = Sequential()\n",
    "qrnn4.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE,\n",
    "                   input_length=query_maxlen))\n",
    "qrnn4.add(Dropout(0.3))\n",
    "qrnn4.add(RNN(EMBED_HIDDEN_SIZE, return_sequences=False))\n",
    "\n",
    "sentrnn4 = Sequential()\n",
    "sentrnn4.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE,\n",
    "                      input_length=story_maxlen))\n",
    "sentrnn4.add(Dropout(0.3))\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Merge([sentrnn, qrnn], mode='sum'))\n",
    "model4.add(Dropout(0.3))\n",
    "model4.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "# For a multi-class classification problem\n",
    "model4.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Training')\n",
    "history4 = model4.fit([X, Xq], Y, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, validation_split=0.05)\n",
    "loss, acc = model4.evaluate([tX, tXq], tY, batch_size=BATCH_SIZE)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))\n",
    "print(\"%s: %.2f%%\" % (model4.metrics_names[1], acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4.summary()\n",
    "print (history4.params)\n",
    "\n",
    "y_acc4 = history4.history[\"acc\"]\n",
    "y_accVal4 = history4.history['val_acc']\n",
    "\n",
    "p.plot(x,y_acc4, label='Train')\n",
    "p.plot(x,y_accVal4, label='Test')\n",
    "p.legend(bbox_to_anchor=(1, -1),\n",
    "           bbox_transform=p.gcf().transFigure)\n",
    "title = 'Model LSTM + Dense relu' + '\\nAccuracy' + '\\nEMBED_HIDDEN_SIZE = 100'\n",
    "p.title(title)\n",
    "\n",
    "p.show()\n",
    "\n",
    "y_loss4 = history4.history[\"loss\"]\n",
    "y_lossVal4 = history4.history['val_loss']\n",
    "p.plot(x, y_loss4, label='Train')\n",
    "p.plot(x, y_lossVal4, label='Test')\n",
    "p.legend(bbox_to_anchor=(1, -1),\n",
    "           bbox_transform=p.gcf().transFigure)\n",
    "title = 'Model LSTM + Dense relu' + '\\nLoss'  + '\\nEMBED_HIDDEN_SIZE = 100'\n",
    "p.title(title)\n",
    "\n",
    "p.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
